# ai_gateway_service.py
# AIç½‘å…³æœåŠ¡ - è´Ÿè´£Luaè„šæœ¬ä¸AIæ¨¡å‹æœåŠ¡ä¹‹é—´çš„é€šä¿¡åè°ƒ
from collections import defaultdict
import requests
import json
import time
from datetime import datetime
import redis
from flask import Flask, request, jsonify
from config.setting import settings
from common.logger import setup_logger
import threading

app = Flask(__name__)
logger = setup_logger('ai_gateway', category='gateway', console_output=True)

# æœåŠ¡é…ç½®
AI_MODEL_SERVICE_URL = settings.AI_MODEL_SERVICE_URL  # AIæ¨¡å‹æœåŠ¡åœ°å€
GATEWAY_VERSION = "1.0.0"

# Redisè¿æ¥
redis_pool = redis.ConnectionPool(
    host=settings.REDIS_SERVER,
    password=settings.REDIS_PASSWORD,
    port=settings.REDIS_PORT,
    db=settings.REDIS_DB,
    decode_responses=True,
    max_connections=50
)
redis_client = redis.Redis(connection_pool=redis_pool)


class GatewayManager:
    """ç½‘å…³ç®¡ç†å™¨"""

    def __init__(self):
        # ğŸ¯ ç›´æ¥ä½¿ç”¨å¯åºåˆ—åŒ–çš„æ•°æ®ç»“æ„
        self.stats = {
            'total_calls': 0,
            'successful_calls': 0,
            'failed_calls': 0,
            'active_tasks': []  # ç›´æ¥ä½¿ç”¨åˆ—è¡¨è€Œä¸æ˜¯ set
        }
        self.task_model_map = {}
        self.model_tasks = defaultdict(list)  # ä½¿ç”¨åˆ—è¡¨è€Œä¸æ˜¯ set

        # ğŸ¯ å†…éƒ¨ä½¿ç”¨ set ç”¨äºå¿«é€ŸæŸ¥æ‰¾ï¼ˆä¸æš´éœ²ç»™ JSONï¼‰
        self._active_tasks_set = set()
        self._model_tasks_set = defaultdict(set)

    def record_call(self, success=True):
        """è®°å½•å‘¼å«ç»Ÿè®¡"""
        self.stats['total_calls'] += 1
        if success:
            self.stats['successful_calls'] += 1
        else:
            self.stats['failed_calls'] += 1

    def bind_task_to_model(self, task_id, model_id):
        if task_id in self.task_model_map:
            existing_model_id = self.task_model_map[task_id]
            if existing_model_id != model_id:
                logger.warning(f"ä»»åŠ¡ {task_id} ä»æ¨¡å‹ {existing_model_id} åˆ‡æ¢åˆ° {model_id}")
                self.unbind_task(task_id)

        # ğŸ¯ åŒæ—¶æ›´æ–°å†…éƒ¨ set å’Œå¤–éƒ¨åˆ—è¡¨
        self._active_tasks_set.add(task_id)
        if task_id not in self.stats['active_tasks']:
            self.stats['active_tasks'].append(task_id)

        self._model_tasks_set[model_id].add(task_id)
        if task_id not in self.model_tasks[model_id]:
            self.model_tasks[model_id].append(task_id)

        self.task_model_map[task_id] = model_id
        logger.info(f"ğŸ”— ä»»åŠ¡ç»‘å®šåˆ°æ¨¡å‹ - ä»»åŠ¡: {task_id}, æ¨¡å‹: {model_id}")

    def unbind_task(self, task_id):
        # ğŸ¯ åŒæ—¶æ›´æ–°å†…éƒ¨ set å’Œå¤–éƒ¨åˆ—è¡¨
        if task_id in self._active_tasks_set:
            self._active_tasks_set.remove(task_id)
        if task_id in self.stats['active_tasks']:
            self.stats['active_tasks'].remove(task_id)

        if task_id in self.task_model_map:
            model_id = self.task_model_map[task_id]
            del self.task_model_map[task_id]

            if model_id in self._model_tasks_set and task_id in self._model_tasks_set[model_id]:
                self._model_tasks_set[model_id].remove(task_id)
            if model_id in self.model_tasks and task_id in self.model_tasks[model_id]:
                self.model_tasks[model_id].remove(task_id)

    # ğŸ¯ ä¸å†éœ€è¦ç‰¹æ®Šçš„åºåˆ—åŒ–æ–¹æ³•
    # å› ä¸ºæ‰€æœ‰æ•°æ®ç»“æ„å·²ç»æ˜¯å¯åºåˆ—åŒ–çš„


# å…¨å±€ç½‘å…³ç®¡ç†å™¨
gateway_manager = GatewayManager()


def async_initialize_model(model_id, config_data, expire_time):
    """å¼‚æ­¥åˆå§‹åŒ–æ¨¡å‹"""

    def initialize_task():
        try:
            payload = {
                'model_id': model_id,
                'config': config_data or {},
                'expire_time': expire_time
            }

            logger.info(f"ğŸ”„ å¼€å§‹å¼‚æ­¥åˆå§‹åŒ–æ¨¡å‹: {model_id}")
            response = requests.post(
                f"{AI_MODEL_SERVICE_URL}/model/initialize",
                json=payload,
                timeout=60  # åˆå§‹åŒ–å¯èƒ½è¾ƒæ…¢
            )

            if response.status_code == 200:
                result = response.json()
                if result['success']:
                    logger.info(f"âœ… å¼‚æ­¥æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {model_id}")
                else:
                    logger.error(f"âŒ å¼‚æ­¥æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {model_id}, é”™è¯¯: {result.get('message')}")
            else:
                logger.error(f"âŒ å¼‚æ­¥æ¨¡å‹åˆå§‹åŒ–HTTPé”™è¯¯: {model_id}, çŠ¶æ€ç : {response.status_code}")

        except Exception as e:
            logger.error(f"ğŸš¨ å¼‚æ­¥æ¨¡å‹åˆå§‹åŒ–å¼‚å¸¸: {model_id}, é”™è¯¯: {str(e)}")

    # å¯åŠ¨å¼‚æ­¥çº¿ç¨‹
    thread = threading.Thread(target=initialize_task, daemon=True, name=f"AsyncInit-{model_id}")
    thread.start()
    logger.info(f"ğŸš€ æäº¤å¼‚æ­¥æ¨¡å‹åˆå§‹åŒ–ä»»åŠ¡: {model_id}")


def call_model_service(model_id, backstop_model, user_input, conversation_history, call_id, task_id):
    """è°ƒç”¨AIæ¨¡å‹æœåŠ¡ç”Ÿæˆè¯æœ¯ ï¼Œè¿”å›(å“åº”, å†å², å®é™…ä½¿ç”¨çš„æ¨¡å‹ID)"""
    # å®Œå–„å“åº”å¤„ç†******
    # result['response'] = [
    #   {},{},{}, -- å†å²å¯¹è¯
    #   {
    #       "role": "assistant", è§’è‰²
    #       "content": "", å›å¤è¯æœ¯
    #       'intention_tag': '', å›å¤è¯æœ¯æ‰€åœ¨æµç¨‹çš„æ„å‘æ ‡ç­¾
    #       'dialog_id': '', è¯æœ¯id
    #       'logic': {
    #           'user_logic_title':{'ä¸»çº¿æµç¨‹ã€è‚¯å®šã€‘åˆ†æ”¯ â€œè‚¯å®šâ€', 'å¤§æ¨¡å‹ç†è§£ï¼šâ€œå®¢æˆ·è¡¨ç¤ºæƒ³è¦äº†è§£è£…ä¿®â€'},
    #           'assistant_logic_title':'ã€ä¸»çº¿æµç¨‹ã€‘ï¼šä¸»æµç¨‹äºŒä¸šåŠ¡ä»‹ç»ã€è‚¯å®š -> ä¸»çº¿æµç¨‹è·³è½¬ä¸‹ä¸€ä¸»çº¿æµç¨‹',
    #           'detail': [
    #               {'master_id':'ä¸»æµç¨‹id','branch_id':'èŠ‚ç‚¹id', 'hit_branch_id':'å‘½ä¸­çš„åˆ†æ”¯çš„id', 'infer_type': 'æ¨ç†çš„ç±»å‹': '1 æ„å›¾ 2 çŸ¥è¯†åº“', 'infer_use_id':'æ„å›¾/çŸ¥è¯†åº“id', 'infer_use_type': 'çŸ¥è¯†åº“çš„ç±»å‹1é€šç”¨é—®é¢˜ 2ä¸šåŠ¡é—®é¢˜ 3ä¸€èˆ¬é—®é¢˜'},
    #               {'master_id':'ä¸»æµç¨‹id','branch_id':'èŠ‚ç‚¹id', 'hit_branch_id':'å‘½ä¸­çš„åˆ†æ”¯1è‚¯å®š2å¦å®š3æ‹’æ¥4æ— åº”ç­”5é»˜è®¤', 'infer_type': 'æ¨ç†çš„ç±»å‹': '1 æ„å›¾ 2 çŸ¥è¯†åº“', 'infer_use_id':'æ„å›¾/çŸ¥è¯†åº“id', 'infer_use_type': 'çŸ¥è¯†åº“çš„ç±»å‹1é€šç”¨é—®é¢˜ 2ä¸šåŠ¡é—®é¢˜ 3ä¸€èˆ¬é—®é¢˜'}
    #           ]
    #       },
    #   }]
    # è¿˜éœ€è¦ çŸ¥é“ ç”¨æˆ·çš„è¯æœ¯æ˜¯è‚¯å®šè¿˜æ˜¯å¦å®š  ç”¨ logic.detail é‡Œæœ€åä¸€æ¡çš„ hit_branch_id çš„ç±»å‹
    # ä¸»æµç¨‹å®Œæˆæ¬¡æ•° å‡ºç°çš„æ‰€æœ‰master_id ç®—æ¬¡æ•°
    #
    try:
        payload = {
            'model_id': model_id,
            'backstop_model': backstop_model,
            'user_input': user_input,
            'conversation_history': conversation_history,
            'call_id': call_id,
            'task_id': task_id
        }

        start_time = time.time()
        response = requests.post(
            f"{AI_MODEL_SERVICE_URL}/model/generate",
            json=payload,
            timeout=10
        )
        response_time = (time.time() - start_time) * 1000  # æ¯«ç§’

        if response.status_code == 200:
            result = response.json()
            if result['success']:
                logger.info(f"ğŸ¯ AIå“åº”æˆåŠŸ - ä»»åŠ¡: {task_id}, å‘¼å«: {call_id}, è€—æ—¶: {response_time:.1f}ms")
                gateway_manager.record_call(success=True)
                # ğŸ¯ è¿”å›å®é™…ä½¿ç”¨çš„æ¨¡å‹ID
                actual_model_id = result.get('model_id', model_id)
                return result['response'], result['conversation_history'], actual_model_id
            else:
                logger.error(f"âŒ AIæœåŠ¡ä¸šåŠ¡é”™è¯¯: {result.get('message')}")
        elif response.status_code == 404:
            logger.error(f"ğŸ” æ¨¡å‹æœªæ‰¾åˆ° - æ¨¡å‹: {model_id}, ä»»åŠ¡: {task_id}")
            gateway_manager.record_call(success=False)
        else:
            logger.error(f"âŒ AIæœåŠ¡HTTPé”™è¯¯: {response.status_code}")

    except requests.exceptions.RequestException as e:
        logger.error(f"ğŸ”Œ è°ƒç”¨AIæ¨¡å‹æœåŠ¡å¤±è´¥: {str(e)}")
        gateway_manager.record_call(success=False)
        # ğŸ¯ å¢å¼ºï¼šè®°å½•æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        error_detail = {
            'main_model': model_id,
            'backstop_model': backstop_model,
            'error': str(e),
            'call_id': call_id,
            'task_id': task_id
        }
        logger.error(f"ğŸš¨ æ‰€æœ‰æ¨¡å‹éƒ½ä¸å¯ç”¨: {json.dumps(error_detail)}")

    # é»˜è®¤è¿”å›å…œåº•æ¨¡å‹
    default_response = "æ‚¨å¥½ï¼Œç³»ç»Ÿæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™ã€‚"
    return default_response, conversation_history, backstop_model


def calculate_tts_duration(text, speed=1.0):
    """è®¡ç®—TTSè¯­éŸ³æ—¶é•¿"""
    if not text:
        return 0
    chinese_chars = len([c for c in text if '\u4e00' <= c <= '\u9fff'])
    english_chars = len([c for c in text if c.isalpha()])
    punctuation = len([c for c in text if c in 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š,.!?;:'])

    base_duration = (chinese_chars / 4 + english_chars / 2) / speed
    pause_duration = punctuation * 0.3
    total_duration = base_duration + pause_duration

    return max(1.0, round(total_duration, 2))


@app.route('/gateway/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        # æ£€æŸ¥AIæ¨¡å‹æœåŠ¡çŠ¶æ€
        model_health = requests.get(f"{AI_MODEL_SERVICE_URL}/health", timeout=5)
        model_status = model_health.json() if model_health.status_code == 200 else {'status': 'unreachable'}

        # æ£€æŸ¥Redisè¿æ¥
        redis_status = 'healthy' if redis_client.ping() else 'unhealthy'

    except Exception as e:
        model_status = {'status': f'unreachable: {str(e)}'}
        redis_status = 'unhealthy'

    return jsonify({
        'status': 'healthy',
        'service': 'ai_gateway',
        'version': GATEWAY_VERSION,
        'timestamp': datetime.now().isoformat(),
        'dependencies': {
            'ai_model_service': model_status,
            'redis': redis_status
        },
        'statistics': gateway_manager.stats
    })


@app.route('/gateway/model/start', methods=['POST'])
def start_model():
    """åˆå§‹åŒ–æ¨¡å‹æ¥å£ - å¼‚æ­¥ç‰ˆæœ¬"""
    data = request.json
    model_id = data.get('model_id')
    config_data = data.get('config_data', {})
    expire_time = data.get('expire_time')
    only_delay = data.get('only_delay', False)

    if not model_id:
        return jsonify({
            'success': False,
            'message': 'model_id å‚æ•°ä¸èƒ½ä¸ºç©º'
        }), 400

    logger.info(f"ğŸš€ æ¥æ”¶æ¨¡å‹å¯åŠ¨è¯·æ±‚ - æ¨¡å‹: {model_id}, ä»…å»¶æœŸ: {only_delay}")

    if only_delay:
        # åªå»¶æœŸæ¨¡å¼ - åŒæ­¥å¤„ç†ï¼ˆå¿«é€Ÿï¼‰
        try:
            payload = {
                'model_id': model_id,
                'expire_time': expire_time,
                'action': 'extend_only'
            }
            response = requests.post(
                f"{AI_MODEL_SERVICE_URL}/model/extend",
                json=payload,
                timeout=10
            )
            if response.status_code == 200 and response.json().get('success'):
                return jsonify({
                    'success': True,
                    'message': f'æ¨¡å‹ {model_id} è¿‡æœŸæ—¶é—´å·²å»¶é•¿',
                    'model_id': model_id
                })
            else:
                return jsonify({
                    'success': False,
                    'message': f'æ¨¡å‹ {model_id} å»¶æœŸå¤±è´¥'
                }), 500
        except Exception as e:
            return jsonify({
                'success': False,
                'message': f'æ¨¡å‹å»¶æœŸè¯·æ±‚å¤±è´¥: {str(e)}'
            }), 500
    else:
        # å®Œæ•´åˆå§‹åŒ–æ¨¡å¼ - å¼‚æ­¥å¤„ç†
        async_initialize_model(model_id, config_data, expire_time)
        return jsonify({
            'success': True,
            'message': f'æ¨¡å‹ {model_id} åˆå§‹åŒ–è¯·æ±‚å·²æäº¤ï¼Œæ­£åœ¨åå°å¤„ç†',
            'model_id': model_id,
            'async': True
        })


# å…¶ä»–æ¥å£ä¿æŒä¸å˜...
@app.route('/gateway/conversation', methods=['POST'])
def conversation():
    """å¯¹è¯æ¥å£"""
    data = request.json
    call_id = data.get('call_id')
    model_id = data.get('model_id', 'default')
    backstop_model = data.get('backstop_model', 'default')
    task_id = data.get('task_id')
    current_input = data.get('current_input', '')

    if not task_id:
        return jsonify({
            'success': False,
            'message': 'task_id å‚æ•°ä¸èƒ½ä¸ºç©º'
        }), 400

    logger.info(f"ğŸ“ å¤„ç†å¯¹è¯è¯·æ±‚ - ä»»åŠ¡: {task_id}, å‘¼å«: {call_id}")

    # ä»Redisè·å–å¯¹è¯å†å²
    conversation_key = f"call:conversation:{call_id}"
    try:
        existing_conversation = redis_client.get(conversation_key)
    except redis.RedisError as e:
        logger.error(f"ğŸ”´ Redisè¿æ¥å¼‚å¸¸: {str(e)}")
        # ğŸ¯ é™çº§å¤„ç†ï¼šä½¿ç”¨ç©ºçš„å†å²è®°å½•ç»§ç»­å¤„ç†
        conversation_history = []
        existing_conversation = None

    if existing_conversation:
        conversation_data = json.loads(existing_conversation)
        conversation_history = conversation_data.get('messages', [])
        # ğŸ¯ æ£€æŸ¥ä¹‹å‰æ˜¯å¦å·²ç»åˆ‡æ¢åˆ°å…œåº•æ¨¡å‹
        actual_model_id = conversation_data.get('actual_model_id', model_id)
    else:
        conversation_history = []
        actual_model_id = model_id  # åˆå§‹ä½¿ç”¨ä¸»æ¨¡å‹
        conversation_data = {
            'call_id': call_id,
            'task_id': task_id,
            'model_id': model_id,
            'actual_model_id': actual_model_id,  # ğŸ¯ æ–°å¢ï¼šè®°å½•å®é™…ä½¿ç”¨çš„æ¨¡å‹
            'backstop_model': backstop_model,
            'start_time': time.time(),
            'messages': conversation_history
        }

    # è°ƒç”¨AIæ¨¡å‹æœåŠ¡ç”Ÿæˆè¯æœ¯
    ai_response, updated_history, used_model_id = call_model_service(
        actual_model_id, backstop_model, current_input, conversation_history, call_id, task_id
    )
    # ğŸ¯ æ›´æ–°å®é™…ä½¿ç”¨çš„æ¨¡å‹IDï¼ˆå¦‚æœå‘ç”Ÿäº†åˆ‡æ¢ï¼‰
    if used_model_id != actual_model_id:
        old_model_id = actual_model_id
        actual_model_id = used_model_id
        logger.info(f"ğŸ”„ æ¨¡å‹åˆ‡æ¢: {old_model_id} -> {actual_model_id}")
    # æ›´æ–°å¯¹è¯å†å²åˆ°Redis
    conversation_data['messages'] = updated_history
    conversation_data['actual_model_id'] = actual_model_id  # ğŸ¯ æ›´æ–°å®é™…æ¨¡å‹
    conversation_data['last_update'] = time.time()
    redis_client.setex(conversation_key, 3600, json.dumps(conversation_data))

    # è‡ªåŠ¨ç»‘å®šä»»åŠ¡åˆ°å®é™…ä½¿ç”¨çš„æ¨¡å‹
    gateway_manager.bind_task_to_model(task_id, actual_model_id)

    # æ„å»ºæ··åˆæ’­æ”¾å†…å®¹
    mixed_content = {
        'playback_type': 'tts_only',
        'content': [
            {
                'type': 'tts',
                'value': ai_response,
                'duration': calculate_tts_duration(ai_response)
            }
        ],
        'total_duration': calculate_tts_duration(ai_response),
        'allow_bargein': True
    }

    # åŠ¨æ€ASRå‚æ•°
    dynamic_params = {
        'asr_no_input_timeout': int((calculate_tts_duration(ai_response) + 2) * 1000),
        'asr_speech_timeout': 15000,
        'asr_silence_threshold': 25,
        'asr_sensitivity': 0.8,
        'tts_voice': 'xiaoyan',
        'tts_speed': 1.0,
        'barge_in_enabled': True,
        'estimated_total_duration': calculate_tts_duration(ai_response)
    }

    response = {
        'success': True,
        'action': 'speak',
        'content': mixed_content,
        'dynamic_params': dynamic_params,
        'next_step': 'wait_input',
        'variables': {},
        'end_call': False,
        'current_turn': len([msg for msg in updated_history if msg['role'] == 'assistant']),
        'task_id': task_id,
        'model_id': actual_model_id,  # ğŸ¯ è¿”å›å®é™…ä½¿ç”¨çš„æ¨¡å‹ID
        'call_id': call_id
    }

    logger.info(f"âœ… å¯¹è¯å“åº”ç”Ÿæˆ - ä»»åŠ¡: {task_id}, å‘¼å«: {call_id}")
    return jsonify(response)


def check_model_service_health():
    """æ£€æŸ¥AIæ¨¡å‹æœåŠ¡å¥åº·çŠ¶æ€"""
    try:
        response = requests.get(f"{AI_MODEL_SERVICE_URL}/health", timeout=5)
        if response.status_code == 200:
            health_data = response.json()
            logger.info(f"âœ… AIæ¨¡å‹æœåŠ¡çŠ¶æ€: {health_data.get('status', 'unknown')}")
            logger.info(f"ğŸ“Š å½“å‰æ¨¡å‹æ•°: {health_data.get('model_stats', {}).get('total_models', 0)}")
            return True
        else:
            logger.warning(f"âš ï¸ AIæ¨¡å‹æœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"âŒ æ— æ³•è¿æ¥åˆ°AIæ¨¡å‹æœåŠ¡: {str(e)}")
        return False

def start_gateway_service(port=5001):
    """å¯åŠ¨AIç½‘å…³æœåŠ¡"""
    logger.info(f"ğŸš€ å¯åŠ¨AIç½‘å…³æœåŠ¡ï¼Œç«¯å£: {port}")
    logger.info(f"ğŸ“‹ æœåŠ¡ç‰ˆæœ¬: {GATEWAY_VERSION}")
    logger.info(f"ğŸ”— AIæ¨¡å‹æœåŠ¡: {AI_MODEL_SERVICE_URL}")
    logger.info("âœ… ç½‘å…³æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œç­‰å¾…è¯·æ±‚...")
    # ğŸ¯ æ£€æŸ¥ä¾èµ–æœåŠ¡çŠ¶æ€
    if not check_model_service_health():
        logger.warning("âš ï¸ AIæ¨¡å‹æœåŠ¡å¯èƒ½ä¸å¯ç”¨ï¼Œä½†ç½‘å…³æœåŠ¡å°†ç»§ç»­å¯åŠ¨")

    app.run(host='0.0.0.0', port=port, debug=False, threaded=True)


if __name__ == '__main__':
    start_gateway_service()
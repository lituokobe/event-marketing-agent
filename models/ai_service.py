# ai_service.py
from flask import Flask, request, jsonify
import requests
import threading
import time
from datetime import datetime, timedelta
import json
from collections import defaultdict
import psutil
import os
import shutil
from agent_builders.chatflow_builder import build_chatflow
from config.config_setup import ChatFlowConfig
from config.paths import AGENT_DATA_PATH, INTENTION_PATH, KNOWLEDGE_PATH, DB_PATH, CHATFLOW_DESIGN_PATH, DIALOG_PATH
from functionals.log_utils import logger_chatflow
from functionals.state import ChatState
from config.setting import settings
from models.async_notification_manager import AsyncNotificationManager
from models.persistence_manager import ModelPersistenceManager

app = Flask(__name__)

PHP_CALLBACK_URL = settings.PHP_CALLBACK_URL  # PHPå›è°ƒåœ°å€


class DynamicModelManager:
    def __init__(self):
        self.models = {}  # {model_id: model_data}
        self.model_usage = defaultdict(int)  # æ¨¡å‹ä½¿ç”¨è®¡æ•°
        self.model_last_used = {}  # æ¨¡å‹æœ€åä½¿ç”¨æ—¶é—´
        self.model_tasks = defaultdict(set)  # æ¨¡å‹å…³è”çš„ä»»åŠ¡
        self.model_created_time = {}  # ğŸ¯ è®°å½•æ¨¡å‹åˆ›å»ºæ—¶é—´
        self.lock = threading.RLock()

        # ğŸ¯ æŒä¹…åŒ–ç®¡ç†å™¨
        self.persistence_manager = ModelPersistenceManager()
        # å¼‚æ­¥é€šçŸ¥ç®¡ç†å™¨
        self.notification_manager = AsyncNotificationManager(max_workers=5)

        # èµ„æºé…ç½®
        self.max_models = 50
        self.max_memory_mb = 4096  # ğŸ¯ æ–°å¢ï¼šæœ€å¤§å†…å­˜é™åˆ¶ 2GB
        self.model_timeout = 3600
        self.cleanup_interval = 300
        self.model_memory_estimate = 100  # ğŸ¯ æ¯ä¸ªæ¨¡å‹é¢„ä¼°å†…å­˜å ç”¨(MB)

        # ğŸ¯ å¯åŠ¨æ—¶æ¢å¤æ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
        self._recover_models_on_startup()

        # å¯åŠ¨åå°æ¸…ç†çº¿ç¨‹
        self._start_cleanup_thread()

    def _start_cleanup_thread(self):
        """å¯åŠ¨åå°æ¸…ç†çº¿ç¨‹"""

        def cleanup_worker():
            while True:
                time.sleep(self.cleanup_interval)
                try:
                    # ğŸ¯ å…ˆæ£€æŸ¥æ˜¯å¦éœ€è¦ç´§æ€¥æ¸…ç†
                    emergency_result = self.check_and_cleanup_if_needed()
                    if emergency_result.get('cleaned', False):
                        logger_chatflow.debug(f"ğŸ”„ ç´§æ€¥æ¸…ç†å®Œæˆ: {emergency_result}")

                    # ğŸ¯ ç„¶åè¿›è¡Œå¸¸è§„æ¸…ç†
                    normal_result = self.cleanup_idle_models()  # æ­£å¸¸æ¸…ç†
                    if normal_result['removed_count'] > 0:
                        logger_chatflow.debug(f"ğŸ”„ å¸¸è§„æ¸…ç†å®Œæˆ: ç§»é™¤äº† {normal_result['removed_count']} ä¸ªæ¨¡å‹")

                except Exception as e:
                    logger_chatflow.error(f"æ¸…ç†çº¿ç¨‹å¼‚å¸¸: {str(e)}")

        thread = threading.Thread(target=cleanup_worker, daemon=True)
        thread.start()

    def _notify_php_model_activated(self, model_id):
        """å¼‚æ­¥é€šçŸ¥PHPæ¨¡å‹æ¿€æ´»"""
        try:
            payload = {
                'model_id': model_id,
                'status': 'activated',
                'timestamp': datetime.now().isoformat()
            }
            # ä½¿ç”¨å¼‚æ­¥çº¿ç¨‹
            thread = threading.Thread(
                target=lambda: requests.post(f"{PHP_CALLBACK_URL}", json=payload, timeout=3),
                daemon=True
            )
            thread.start()
            logger_chatflow.info(f"ğŸ“¤ å¼‚æ­¥é€šçŸ¥PHPæ¨¡å‹æ¿€æ´»: {model_id}")
        except Exception as e:
            logger_chatflow.error(f"âŒ å¼‚æ­¥é€šçŸ¥PHPæ¨¡å‹æ¿€æ´»å¤±è´¥: {str(e)}")

    def _notify_php_model_activation_failed(self, model_id, error_msg):
        """é€šçŸ¥PHPæ¨¡å‹æ¿€æ´»å¤±è´¥"""
        try:
            payload = {
                'model_id': model_id,
                'status': 'sleep',  # å›é€€åˆ°ä¼‘çœ çŠ¶æ€
                'timestamp': datetime.now().isoformat(),
                'reason': f'activation_failed: {error_msg}'
            }
            # ä½¿ç”¨å¼‚æ­¥çº¿ç¨‹å‘é€é€šçŸ¥
            thread = threading.Thread(
                target=lambda: requests.post(f"{PHP_CALLBACK_URL}", json=payload, timeout=3),
                daemon=True
            )
            thread.start()
            logger_chatflow.info(f"ğŸ“¤ é€šçŸ¥PHPæ¨¡å‹æ¿€æ´»å¤±è´¥: {model_id}, åŸå› : {error_msg}")
        except Exception as e:
            logger_chatflow.error(f"âŒ é€šçŸ¥PHPæ¨¡å‹æ¿€æ´»å¤±è´¥å¤±è´¥: {str(e)}")

    def _notify_php_model_sleep(self, model_id):
        """å¼‚æ­¥é€šçŸ¥PHPæ¨¡å‹ä¼‘çœ """
        payload = {
            'model_id': model_id,
            'status': 'sleep',
            'timestamp': datetime.now().isoformat(),
            'reason': 'no_active_tasks_or_expired'
        }
        self.notification_manager.add_notification(
            f"{PHP_CALLBACK_URL}",
            payload,
            "model_sleep"
        )

    def notify_php_task_pause(self, task_id, model_id, reason):
        """å¼‚æ­¥é€šçŸ¥PHPæš‚åœä»»åŠ¡"""
        try:
            payload = {
                'task_id': task_id,
                'model_id': model_id,
                'status': 'pause_task',
                'reason': reason,
                'timestamp': datetime.now().isoformat()
            }
            # ä½¿ç”¨å¼‚æ­¥çº¿ç¨‹
            thread = threading.Thread(
                target=lambda: requests.post(f"{PHP_CALLBACK_URL}", json=payload, timeout=3),
                daemon=True
            )
            thread.start()
            logger_chatflow.warning(f"ğŸ“¤ å¼‚æ­¥é€šçŸ¥PHPæš‚åœä»»åŠ¡: {task_id}, åŸå› : {reason}")
        except Exception as e:
            logger_chatflow.error(f"âŒ å¼‚æ­¥é€šçŸ¥PHPæš‚åœä»»åŠ¡å¤±è´¥: {str(e)}")

    def _recover_models_on_startup(self):
        """æœåŠ¡å¯åŠ¨æ—¶æ¢å¤æ¨¡å‹ - ç®€åŒ–ç‰ˆæœ¬"""
        logger_chatflow.info("ğŸ”„ å¼€å§‹æ¢å¤æŒä¹…åŒ–çš„æ¨¡å‹...")

        # åŠ è½½æ¨¡å‹é…ç½®
        model_configs = self.persistence_manager.load_model_configs()
        recovered_count = 0
        expired_count = 0

        for model_id, config_data in model_configs.items():
            try:
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿‡æœŸ
                current_time = time.time()
                expire_time = config_data.get('expire_time', 0)

                if current_time > expire_time:
                    logger_chatflow.info(f"ğŸ—‘ï¸ è·³è¿‡è¿‡æœŸæ¨¡å‹å¹¶åˆ é™¤é…ç½®: {model_id}")
                    self.persistence_manager.delete_model_config(model_id)
                    expired_count += 1
                    continue

                # é‡æ–°åˆå§‹åŒ–æ¨¡å‹
                chatflow_config = self._build_chatflow_config(config_data.get('config', {}))
                chatflow = build_chatflow(chatflow_config)

                # æ¢å¤æ¨¡å‹æ•°æ®
                self.models[model_id] = {
                    'instance': chatflow,
                    'config': config_data.get('config', {}),
                    'created_time': config_data.get('created_time', datetime.now()),
                    'expire_time': expire_time,
                    'memory_usage': config_data.get('memory_usage', 0),
                    'status': 'recovered'
                }

                # æ¢å¤ä½¿ç”¨ç»Ÿè®¡ï¼ˆé‡ç½®ä¸º0ï¼Œå› ä¸ºæœåŠ¡é‡å¯ï¼‰
                self.model_usage[model_id] = 0
                self.model_last_used[model_id] = config_data.get('last_used', datetime.now())
                self.model_created_time[model_id] = config_data.get('created_time', datetime.now())

                recovered_count += 1
                logger_chatflow.info(f"âœ… æ¢å¤æ¨¡å‹æˆåŠŸ: {model_id}")

            except Exception as e:
                logger_chatflow.error(f"âŒ æ¢å¤æ¨¡å‹å¤±è´¥ {model_id}: {str(e)}")
                continue

        logger_chatflow.info(f"ğŸ‰ æ¨¡å‹æ¢å¤å®Œæˆ: æˆåŠŸ {recovered_count} ä¸ª, è¿‡æœŸ {expired_count} ä¸ª")

    def initialize_model(self, model_id, config_data=None, task_id=None, expire_time=None):
        """åŠ¨æ€åˆå§‹åŒ–æ¨¡å‹"""
        with self.lock:
            # æ£€æŸ¥æ˜¯å¦å·²è¾¾æ¨¡å‹ä¸Šé™
            if len(self.models) >= self.max_models:
                # å°è¯•æ¸…ç†ç©ºé—²æ¨¡å‹
                self.cleanup_idle_models(force_reason='count_exceed')
                if len(self.models) >= self.max_models:
                    error_msg = f"æ¨¡å‹æ•°é‡å·²è¾¾ä¸Šé™ {self.max_models}ï¼Œæ— æ³•åˆ›å»ºæ–°æ¨¡å‹"
                    self._notify_php_model_activation_failed(model_id, error_msg)
                    raise Exception(error_msg)

            # å¦‚æœæ¨¡å‹å·²å­˜åœ¨ï¼Œå¢åŠ ä½¿ç”¨è®¡æ•°
            if model_id in self.models:
                self.model_usage[model_id] += 1
                if task_id:
                    self.model_tasks[model_id].add(task_id)
                if expire_time:
                    self.models[model_id]['expire_time'] = expire_time
                logger_chatflow.info(f"æ¨¡å‹ {model_id} å·²å­˜åœ¨ï¼Œå¢åŠ ä½¿ç”¨è®¡æ•°: {self.model_usage[model_id]}")
                return True

            try:
                logger_chatflow.info(f"å¼€å§‹åŠ¨æ€åˆå§‹åŒ–æ¨¡å‹: {model_id}")

                # æ„å»ºé…ç½®
                chatflow_config = self._build_chatflow_config(config_data)
                chatflow = build_chatflow(chatflow_config)

                # å­˜å‚¨æ¨¡å‹å®ä¾‹
                current_time = datetime.now()
                self.models[model_id] = {
                    'instance': chatflow,
                    'config': config_data or {},
                    'created_time': current_time,
                    'expire_time': expire_time or (time.time() + 14 * 24 * 3600),
                    'memory_usage': self._get_memory_usage(),
                    'status': 'active'
                }
                self.model_usage[model_id] = 0  # ğŸ¯ ä¿®æ”¹ï¼šæ–°æ¨¡å‹åˆå§‹è®¡æ•°ä¸º0
                self.model_last_used[model_id] = current_time
                self.model_created_time[model_id] = current_time

                if task_id:
                    self.model_tasks[model_id].add(task_id)
                    self.model_usage[model_id] += 1  # ğŸ¯ å¦‚æœæœ‰task_idï¼Œæ‰å¢åŠ è®¡æ•°

                logger_chatflow.info(f"æ¨¡å‹ {model_id} åŠ¨æ€åˆå§‹åŒ–æˆåŠŸï¼Œå½“å‰æ¨¡å‹æ€»æ•°: {len(self.models)}")

                # ğŸ¯ æŒä¹…åŒ–æ¨¡å‹é…ç½®
                model_persist_data = {
                    'config': config_data or {},
                    'created_time': current_time,
                    'expire_time': expire_time or (time.time() + 14 * 24 * 3600),
                    'memory_usage': self._get_memory_usage(),
                    'status': 'active',
                    'last_used': current_time
                }
                self.persistence_manager.save_model_config(model_id, model_persist_data)

                # é€šçŸ¥PHPæ¨¡å‹æ¿€æ´»
                self._notify_php_model_activated(model_id)
                return True

            except Exception as e:
                logger_chatflow.error(f"æ¨¡å‹ {model_id} åŠ¨æ€åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                # æ¸…ç†å¯èƒ½çš„éƒ¨åˆ†åˆå§‹åŒ–
                if model_id in self.models:
                    del self.models[model_id]
                if model_id in self.model_usage:
                    del self.model_usage[model_id]
                # é€šçŸ¥PHPæ¿€æ´»å¤±è´¥
                self._notify_php_model_activation_failed(model_id, str(e))
                raise

    def get_model(self, model_id, task_id=None):
        """è·å–æ¨¡å‹å®ä¾‹ï¼Œæ›´æ–°ä½¿ç”¨æ—¶é—´"""
        with self.lock:
            if model_id in self.models:
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿‡æœŸ
                if self._check_model_expired(model_id):
                    logger_chatflow.warning(f"æ¨¡å‹ {model_id} å·²è¿‡æœŸ")
                    # é€šçŸ¥PHPæ¨¡å‹ä¼‘çœ     è¿™æ­¥å’Œä¸‹é¢çš„ æš‚åœå¹¶é‡æ–°æ¿€æ´»é‡å¤ notify_php_task_pause
                    # self._notify_php_model_sleep(model_id)
                    return None

                self.model_last_used[model_id] = datetime.now()
                self.model_usage[model_id] += 1
                if task_id and task_id not in self.model_tasks[model_id]:
                    self.model_tasks[model_id].add(task_id)
                return self.models[model_id]['instance']
            return None

    def _check_model_expired(self, model_id):
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿‡æœŸ"""
        if model_id in self.models:
            model_data = self.models[model_id]
            current_time = time.time()
            if current_time > model_data['expire_time']:
                return True
        return False

    def extend_model_expire_time(self, model_id, expire_time):
        """å»¶é•¿æ¨¡å‹è¿‡æœŸæ—¶é—´"""
        with self.lock:
            if model_id in self.models:
                self.models[model_id]['expire_time'] = expire_time
                logger_chatflow.info(f"æ¨¡å‹ {model_id} è¿‡æœŸæ—¶é—´å·²å»¶é•¿è‡³: {expire_time}")
                return True
            return False

    def release_model(self, model_id, task_id=None):
        """é‡Šæ”¾æ¨¡å‹ä½¿ç”¨è®¡æ•°"""
        with self.lock:
            if model_id in self.model_usage:
                self.model_usage[model_id] = max(0, self.model_usage[model_id] - 1)

                # å¦‚æœæŒ‡å®šäº†task_idï¼Œä»ä»»åŠ¡åˆ—è¡¨ä¸­ç§»é™¤
                if task_id and task_id in self.model_tasks[model_id]:
                    self.model_tasks[model_id].remove(task_id)

                logger_chatflow.info(f"é‡Šæ”¾æ¨¡å‹ {model_id} ä½¿ç”¨è®¡æ•°ï¼Œå½“å‰: {self.model_usage[model_id]}")

    def destroy_model(self, model_id, force=False):
        """é”€æ¯æ¨¡å‹å®ä¾‹"""
        with self.lock:
            if model_id not in self.models:
                return True

            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä»»åŠ¡åœ¨ä½¿ç”¨
            if not force and self.model_usage[model_id] > 0:
                logger_chatflow.warning(f"æ¨¡å‹ {model_id} ä»æœ‰ {self.model_usage[model_id]} ä¸ªä»»åŠ¡åœ¨ä½¿ç”¨ï¼Œæ— æ³•é”€æ¯")
                return False

            try:
                # æ¸…ç†æ¨¡å‹èµ„æº
                model_data = self.models[model_id]

                # ä»ç®¡ç†å™¨ä¸­ç§»é™¤
                del self.models[model_id]
                if model_id in self.model_usage:
                    del self.model_usage[model_id]
                if model_id in self.model_last_used:
                    del self.model_last_used[model_id]
                if model_id in self.model_tasks:
                    del self.model_tasks[model_id]

                # ğŸ¯ åˆ é™¤æŒä¹…åŒ–é…ç½®ï¼ˆä¼šè‡ªåŠ¨æ¸…ç†æ—§å¤‡ä»½ï¼‰
                self.persistence_manager.delete_model_config(model_id)

                logger_chatflow.info(f"æ¨¡å‹ {model_id} å·²é”€æ¯ï¼Œå‰©ä½™æ¨¡å‹æ•°: {len(self.models)}")

                # é€šçŸ¥PHPæ¨¡å‹ä¼‘çœ 
                self._notify_php_model_sleep(model_id)
                return True

            except Exception as e:
                logger_chatflow.error(f"é”€æ¯æ¨¡å‹ {model_id} å¤±è´¥: {str(e)}")
                return False

    def cleanup_idle_models(self, force_reason=None):
        """æ™ºèƒ½æ¸…ç†ç©ºé—²æ¨¡å‹
        Args:
            force_reason: å¼ºåˆ¶æ¸…ç†åŸå›  - 'count_exceed', 'memory_exceed', 'manual'
        """
        with self.lock:
            current_time = datetime.now()
            current_memory = self._get_memory_usage()
            total_models = len(self.models)

            # ğŸ¯ æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
            stats = {
                'total_models': total_models,
                'active_models': len([m for m in self.models if self.model_usage[m] > 0]),
                'idle_models': len([m for m in self.models if self.model_usage[m] == 0]),
                'current_memory_mb': current_memory,
                'max_memory_mb': self.max_memory_mb,
                'max_models': self.max_models,
                'force_reason': force_reason
            }

            logger_chatflow.info(f"ğŸ“Š æ¸…ç†å‰çŠ¶æ€: æ¨¡å‹æ€»æ•°={stats['total_models']}, "
                                 f"æ´»è·ƒ={stats['active_models']}, ç©ºé—²={stats['idle_models']}, "
                                 f"å†…å­˜={stats['current_memory_mb']:.1f}MB")

            # ğŸ¯ æŒ‰åˆ›å»ºæ—¶é—´æ’åºçš„ç©ºé—²æ¨¡å‹åˆ—è¡¨ï¼ˆæœ€è€çš„åœ¨å‰ï¼‰
            idle_models = []
            for model_id in self.models:
                if self.model_usage[model_id] == 0:  # åªè€ƒè™‘ç©ºé—²æ¨¡å‹
                    idle_time = (current_time - self.model_last_used[model_id]).total_seconds()
                    created_time = self.model_created_time[model_id]
                    idle_models.append({
                        'model_id': model_id,
                        'created_time': created_time,
                        'idle_time': idle_time,
                        'last_used': self.model_last_used[model_id]
                    })

            # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆæœ€è€çš„åœ¨å‰ï¼‰
            idle_models.sort(key=lambda x: x['created_time'])

            models_to_remove = []
            removal_reason = "normal_timeout"

            # ğŸ¯ æ™ºèƒ½æ¸…ç†å†³ç­–
            if force_reason == 'count_exceed':
                # æ¨¡å‹æ•°é‡è¶…é™ï¼šæ¸…ç†æœ€è€çš„ç©ºé—²æ¨¡å‹ï¼Œç›´åˆ°æ•°é‡è¾¾æ ‡
                target_count = max(1, self.max_models - 5)  # æ¸…ç†åˆ°æ¯”ä¸Šé™å°‘5ä¸ªï¼Œç•™å‡ºç¼“å†²
                excess_count = total_models - target_count

                if excess_count > 0 and idle_models:
                    models_to_remove = idle_models[:min(excess_count, len(idle_models))]
                    removal_reason = f"count_exceed_{excess_count}_over"

            elif force_reason == 'memory_exceed':
                # å†…å­˜è¶…é™ï¼šæ¸…ç†æœ€è€çš„ç©ºé—²æ¨¡å‹ï¼Œç›´åˆ°å†…å­˜è¾¾æ ‡
                target_memory = self.max_memory_mb * 0.8  # æ¸…ç†åˆ°80%çš„å†…å­˜ä½¿ç”¨
                excess_memory = current_memory - target_memory

                if excess_memory > 0 and idle_models:
                    # é¢„ä¼°æ¸…ç†æ•ˆæœï¼šæ¯ä¸ªæ¨¡å‹çº¦é‡Šæ”¾100MB
                    models_needed = min(len(idle_models), int(excess_memory / self.model_memory_estimate) + 1)
                    models_to_remove = idle_models[:models_needed]
                    removal_reason = f"memory_exceed_{excess_memory:.0f}MB_over"

            elif force_reason == 'manual':
                # æ‰‹åŠ¨æ¸…ç†ï¼šæ¸…ç†æ‰€æœ‰è¶…æ—¶ç©ºé—²æ¨¡å‹
                for model_info in idle_models:
                    if model_info['idle_time'] > self.model_timeout:
                        models_to_remove.append(model_info)
                removal_reason = "manual_cleanup"

            else:
                # æ­£å¸¸æ¸…ç†ï¼šåªæ¸…ç†è¶…æ—¶çš„ç©ºé—²æ¨¡å‹
                for model_info in idle_models:
                    if model_info['idle_time'] > self.model_timeout:
                        models_to_remove.append(model_info)
                removal_reason = "normal_timeout"

            # ğŸ¯ æ‰§è¡Œæ¸…ç†
            removed_count = 0
            for model_info in models_to_remove:
                model_id = model_info['model_id']
                if self.destroy_model(model_id, force=True):
                    removed_count += 1
                    logger_chatflow.info(f"ğŸ§¹ æ¸…ç†æ¨¡å‹: {model_id}, "
                                         f"åˆ›å»ºæ—¶é—´: {model_info['created_time'].strftime('%Y-%m-%d %H:%M:%S')}, "
                                         f"ç©ºé—²: {model_info['idle_time']:.0f}ç§’, "
                                         f"åŸå› : {removal_reason}")

            # ğŸ¯ æ¸…ç†åç»Ÿè®¡
            if removed_count > 0:
                after_memory = self._get_memory_usage()
                memory_saved = current_memory - after_memory
                logger_chatflow.info(f"âœ… æ¸…ç†å®Œæˆ: ç§»é™¤äº† {removed_count} ä¸ªæ¨¡å‹, "
                                     f"é‡Šæ”¾å†…å­˜: {memory_saved:.1f}MB, "
                                     f"å‰©ä½™æ¨¡å‹: {len(self.models)}")

                # ğŸ¯ è®°å½•æ¸…ç†æ•ˆæœæ•°æ®ï¼ˆç”¨äºä¼˜åŒ–é…ç½®ï¼‰
                self._record_cleanup_stats({
                    'before_memory': current_memory,
                    'after_memory': after_memory,
                    'memory_saved': memory_saved,
                    'models_removed': removed_count,
                    'reason': removal_reason,
                    'timestamp': datetime.now().isoformat()
                })

            return {
                'removed_count': removed_count,
                'reason': removal_reason,
                'stats_before': stats,
                'stats_after': {
                    'total_models': len(self.models),
                    'current_memory_mb': self._get_memory_usage()
                }
            }

    def check_and_cleanup_if_needed(self):
        """æ£€æŸ¥å¹¶è§¦å‘å¿…è¦çš„æ¸…ç† - ğŸ¯ ç¡®ä¿è¿™ä¸ªæ–¹æ³•è¢«æ­£ç¡®è°ƒç”¨"""
        current_memory = self._get_memory_usage()
        total_models = len(self.models)

        force_reason = None

        # ğŸ¯ å†…å­˜è¶…é™æ£€æŸ¥
        if current_memory > self.max_memory_mb:
            logger_chatflow.warning(f"ğŸš¨ å†…å­˜è¶…é™: {current_memory:.1f}MB > {self.max_memory_mb}MB")
            force_reason = 'memory_exceed'

        # ğŸ¯ æ¨¡å‹æ•°é‡è¶…é™æ£€æŸ¥
        elif total_models > self.max_models:
            logger_chatflow.warning(f"âš ï¸ æ¨¡å‹æ•°é‡è¶…é™: {total_models} > {self.max_models}")
            force_reason = 'count_exceed'

        if force_reason:
            return self.cleanup_idle_models(force_reason=force_reason)

        return {'cleaned': False, 'reason': 'not_needed'}

    def _record_cleanup_stats(self, stats):
        """è®°å½•æ¸…ç†ç»Ÿè®¡ä¿¡æ¯ï¼Œç”¨äºä¼˜åŒ–é…ç½®"""
        # è¿™é‡Œå¯ä»¥å­˜å‚¨åˆ°æ–‡ä»¶æˆ–æ•°æ®åº“ï¼Œç”¨äºåˆ†æå†…å­˜ä½¿ç”¨æ¨¡å¼
        logger_chatflow.debug(f"ğŸ“ˆ æ¸…ç†ç»Ÿè®¡: {json.dumps(stats, default=str)}")

    def _build_chatflow_config(self, config_data):
        """æ ¹æ®é…ç½®æ•°æ®æ„å»ºchatflowé…ç½®"""
        # æ„å»ºchatflowå®ä¾‹ èŒƒæœ¬ æ ¹æ®è¿™ä¸ªæ ·å­å®ä¾‹åŒ–
        # chatflow_data = {
        #     "agent_config": config_data.agent_config,
        #     "keyword_json": config_data.keyword_json,
        #     "semantic_json": config_data.semantic_json,
        #     "llm_json": config_data.llm_json,
        #     "db_path": DB_PATH,
        #     "design_json": config_data.design_json,
        # }
        # chatflow = build_chatflow(chatflow_data)

        # è¿™é‡Œæ ¹æ®å®é™…çš„config_dataæ„å»ºé…ç½®
        if config_data and 'agent_config' in config_data:
            # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
            # chatflow_config = ChatFlowConfig.from_custom_data(
            #     agent_config=config_data.get('agent_config'),
            #     keyword_json=config_data.get('keyword_json'),
            #     semantic_json=config_data.get('semantic_json'),
            #     llm_json=config_data.get('llm_json'),
            #     design_json=config_data.get('design_json')
            # )
            # æµ‹è¯•å…ˆç”¨é»˜è®¤çš„ åˆ°æ—¶å€™æ”¹æˆå®é™…çš„
            chatflow_config = ChatFlowConfig.from_paths(
                AGENT_DATA_PATH,
                INTENTION_PATH,
                KNOWLEDGE_PATH,
                DB_PATH,
                CHATFLOW_DESIGN_PATH,
                DIALOG_PATH
            )
        else:
            # ä½¿ç”¨é»˜è®¤è·¯å¾„é…ç½®
            chatflow_config = ChatFlowConfig.from_paths(
                AGENT_DATA_PATH,
                INTENTION_PATH,
                KNOWLEDGE_PATH,
                DB_PATH,
                CHATFLOW_DESIGN_PATH,
                DIALOG_PATH
            )

        return chatflow_config

    def get_model_status(self, model_id=None):
        """è·å–æ¨¡å‹çŠ¶æ€ - ä¿®å¤JSONåºåˆ—åŒ–é—®é¢˜"""
        with self.lock:
            current_memory = self._get_memory_usage()
            if model_id:
                if model_id in self.models:
                    model_data = self.models[model_id]
                    # ğŸ¯ ä¿®å¤ï¼šå°† set è½¬æ¢ä¸º list ä»¥ä¾¿ JSON åºåˆ—åŒ–
                    associated_tasks = list(self.model_tasks[model_id]) if model_id in self.model_tasks else []

                    return {
                        'model_id': model_id,
                        'status': 'active',
                        'created_time': model_data['created_time'].isoformat(),
                        'last_used': self.model_last_used[model_id].isoformat(),
                        'usage_count': self.model_usage[model_id],
                        'associated_tasks': associated_tasks,  # ğŸ¯ ä½¿ç”¨ list è€Œä¸æ˜¯ set
                        'memory_usage': model_data['memory_usage']
                    }
                else:
                    return {'model_id': model_id, 'status': 'not_found'}
            else:
                # å…¨å±€çŠ¶æ€ - å¢å¼ºä¿¡æ¯
                idle_models = [m for m in self.models if self.model_usage[m] == 0]
                active_models = [m for m in self.models if self.model_usage[m] > 0]

                # è®¡ç®—å†…å­˜ä½¿ç”¨ç»Ÿè®¡
                total_estimated_memory = len(self.models) * self.model_memory_estimate

                # ğŸ¯ ä¿®å¤ï¼šæ„å»ºå¯åºåˆ—åŒ–çš„æ¨¡å‹çŠ¶æ€å­—å…¸
                models_status = {}
                for model_id, data in self.models.items():
                    # ğŸ¯ ä¿®å¤ï¼šå°† set è½¬æ¢ä¸º list
                    associated_tasks_list = list(self.model_tasks[model_id]) if model_id in self.model_tasks else []

                    models_status[model_id] = {
                        'created_time': data['created_time'].isoformat(),
                        'last_used': self.model_last_used[model_id].isoformat(),
                        'usage_count': self.model_usage[model_id],
                        'associated_tasks': associated_tasks_list,  # ğŸ¯ ä½¿ç”¨ list
                        'status': 'active' if self.model_usage[model_id] > 0 else 'idle',
                        'idle_seconds': (datetime.now() - self.model_last_used[
                            model_id]).total_seconds() if model_id in self.model_last_used else 0
                    }

                return {
                    'total_models': len(self.models),
                    'active_models': len(active_models),
                    'idle_models': len(idle_models),
                    'current_memory_mb': current_memory,
                    'max_memory_mb': self.max_memory_mb,
                    'max_models': self.max_models,
                    'memory_usage_percent': (current_memory / self.max_memory_mb) * 100,
                    'model_usage_percent': (len(self.models) / self.max_models) * 100,
                    'estimated_model_memory_mb': total_estimated_memory,
                    'models': models_status  # ğŸ¯ ä½¿ç”¨ä¿®å¤åçš„å­—å…¸
                }

    def _get_memory_usage(self):
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        process = psutil.Process(os.getpid())
        return process.memory_info().rss / 1024 / 1024  # MB

    def check_memory_usage(self):
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œé˜²æ­¢å†…å­˜æ³„æ¼"""
        current_memory = self._get_memory_usage()
        # è¿™é‡Œå¯ä»¥ä¿ç•™ä½œä¸ºç‹¬ç«‹çš„å†…å­˜æ£€æŸ¥ï¼Œä½†æ¸…ç†é€»è¾‘å·²ç»é›†æˆåˆ°æ™ºèƒ½æ¸…ç†ä¸­
        if current_memory > 1024:  # è¶…è¿‡1GB
            logger_chatflow.warning(f"âš ï¸ å†…å­˜ä½¿ç”¨è¾ƒé«˜: {current_memory:.1f}MB")
            # è§¦å‘æ™ºèƒ½æ¸…ç†
            self.check_and_cleanup_if_needed()

        return current_memory

    # ğŸ¯ æ–°å¢ï¼šç£ç›˜ç›‘æ§æ–¹æ³•
    def check_disk_usage(self):
        """æ£€æŸ¥ç£ç›˜ä½¿ç”¨æƒ…å†µï¼Œé˜²æ­¢ç£ç›˜çˆ†æ»¡"""
        disk_info = self.persistence_manager.get_disk_usage()
        if disk_info and disk_info.get('usage_percent', 0) > 90:
            logger_chatflow.warning(f"âš ï¸ ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {disk_info['usage_percent']:.1f}%")
            return False
        return True

    # ğŸ¯ æ–°å¢ï¼šæ‰‹åŠ¨å¤‡ä»½æ¥å£
    def create_manual_backup(self):
        """æ‰‹åŠ¨åˆ›å»ºå¤‡ä»½"""
        return self.persistence_manager.create_manual_backup()


# å…¨å±€åŠ¨æ€æ¨¡å‹ç®¡ç†å™¨
model_manager = DynamicModelManager()


@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ - å¢å¼ºç‰ˆæœ¬"""
    status = model_manager.get_model_status()

    health_status = 'healthy'
    warnings = []

    # ğŸ¯ å¥åº·æ£€æŸ¥é€»è¾‘
    if status['memory_usage_percent'] > 90:
        health_status = 'warning'
        warnings.append(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {status['memory_usage_percent']:.1f}%")

    if status['model_usage_percent'] > 90:
        health_status = 'warning'
        warnings.append(f"æ¨¡å‹æ•°é‡æ¥è¿‘ä¸Šé™: {status['model_usage_percent']:.1f}%")

    return jsonify({
        'status': health_status,
        'service': 'dynamic_ai_service',
        'timestamp': datetime.now().isoformat(),
        'model_stats': status,
        'warnings': warnings,
        'memory_usage': status['current_memory_mb']
    })


@app.route('/model/initialize', methods=['POST'])
def initialize_model():
    """åˆå§‹åŒ–æ¨¡å‹æ¥å£ - åŠ¨æ€åˆ›å»º"""
    data = request.json
    model_id = data.get('model_id')
    config_data = data.get('config', {})
    task_id = data.get('task_id', None)
    expire_time = data.get('expire_time')  # éœ€è¦æ·»åŠ è¿™è¡Œ
    if not model_id:
        return jsonify({
            'success': False,
            'message': 'model_id å‚æ•°ä¸èƒ½ä¸ºç©º'
        }), 400

    try:
        if model_manager.initialize_model(model_id, config_data, task_id, expire_time):
            return jsonify({
                'success': True,
                'message': f'æ¨¡å‹ {model_id} åˆå§‹åŒ–æˆåŠŸ',
                'model_id': model_id,
                'task_id': task_id
            })
        else:
            return jsonify({
                'success': False,
                'message': f'æ¨¡å‹ {model_id} åˆå§‹åŒ–å¤±è´¥'
            }), 500

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æ¨¡å‹ {model_id} åˆå§‹åŒ–å¼‚å¸¸: {str(e)}'
        }), 500


@app.route('/model/extend', methods=['POST'])
def extend_model():
    """å»¶é•¿æ¨¡å‹è¿‡æœŸæ—¶é—´æ¥å£"""
    data = request.json
    model_id = data.get('model_id')
    expire_time = data.get('expire_time')

    if not model_id or not expire_time:
        return jsonify({
            'success': False,
            'message': 'model_id å’Œ expire_time å‚æ•°ä¸èƒ½ä¸ºç©º'
        }), 400

    if model_manager.extend_model_expire_time(model_id, expire_time):
        return jsonify({
            'success': True,
            'message': f'æ¨¡å‹ {model_id} è¿‡æœŸæ—¶é—´å»¶é•¿æˆåŠŸ',
            'model_id': model_id
        })
    else:
        return jsonify({
            'success': False,
            'message': f'æ¨¡å‹ {model_id} æœªæ‰¾åˆ°ï¼Œå»¶é•¿å¤±è´¥'
        }), 404


@app.route('/model/generate', methods=['POST'])
def generate_response():
    """ç”Ÿæˆè¯æœ¯æ¥å£  åŠ å…œåº•æ¨¡å‹é€»è¾‘ ï¼Œä»»åŠ¡idé‡ŒåŒ…å«ä¸€ä¸ªmodel_id å’Œå…œåº•çš„model_id å¤±è´¥çš„è¯ç”¨å…œåº•åœ¨åˆ¤æ–­ä¸€é"""
    data = request.json
    model_id = data.get('model_id')
    backstop_model = data.get('backstop_model')
    user_input = data.get('user_input', '')
    conversation_history = data.get('conversation_history', [])
    call_id = data.get('call_id', 'unknown')
    task_id = data.get('task_id')

    if not model_id:
        return jsonify({
            'success': False,
            'message': 'model_id å‚æ•°ä¸èƒ½ä¸ºç©º'
        }), 400
    # ğŸ¯ è®°å½•å®é™…ä½¿ç”¨çš„æ¨¡å‹ID
    actual_used_model = model_id
    # è·å–æ¨¡å‹å®ä¾‹
    chatflow = model_manager.get_model(model_id, task_id)
    if not chatflow:
        # ä¸å­˜åœ¨ä½¿ç”¨å…œåº•æ¨¡å‹ï¼Œè™½ç„¶model_id å’Œbackstop_modelå¯èƒ½æ˜¯ä¸€ä¸ªä¸å½±å“ï¼Œå¤šåˆ¤æ–­ä¸€æ¬¡çš„äº‹å„¿
        actual_used_model = backstop_model  # ğŸ¯ æ›´æ–°å®é™…ä½¿ç”¨çš„æ¨¡å‹
        chatflow = model_manager.get_model(backstop_model, task_id)
        if not chatflow:
            # æ¨¡å‹æœªæ‰¾åˆ°æˆ–å·²è¿‡æœŸï¼Œé€šçŸ¥PHPæš‚åœä»»åŠ¡
            if task_id:
                model_manager.notify_php_task_pause(task_id, model_id, "model_not_found_or_expired")

            return jsonify({
                'success': False,
                'message': f'æ¨¡å‹ {model_id} å’Œå…œåº•æ¨¡å‹ {backstop_model} éƒ½æœªæ‰¾åˆ°æˆ–å·²è¿‡æœŸ',
                'error_code': 'MODEL_NOT_FOUND'
            }), 404

    try:
        print(conversation_history, 'conversation_history')
        # æ„å»ºå¯¹è¯çŠ¶æ€
        state = ChatState(
            messages=conversation_history.copy(),
            dialog_state=[],
            metadata=[{
                "role":"",
                "content":"",
                "intention_tag":"",
                "dialog_id":"",
                "logic":{
                    "user_logic_title":{},
                    "assistant_logic_title":"",
                    "detail":{}
                }
            }]
        )

        # æ·»åŠ ç”¨æˆ·è¾“å…¥
        if user_input and user_input.strip():
            state["messages"].append({"role": "user", "content": user_input})

        # é…ç½®
        conv_config = {"configurable": {"thread_id": f"call_{call_id}"}}
        print(state, 'ç”Ÿæˆè¯æœ¯çš„è¯·æ±‚å‚æ•°')
        state = chatflow.invoke(state, config=conv_config)
        print(state, 'aiå›å¤è¯¦æƒ…')
        # ç”Ÿæˆå›å¤ ç»“æ„ [å†å²+æœ€æ–°å›å¤ {"role": "user", "content": "", 'logic': '', 'intention_tag': ''}]
        # state["messages"] é‡Œé™¤äº† content å’Œrole è¿˜éœ€è¦æœ‰ å‘½ä¸­é€»è¾‘ logic å’Œ å½“å‰çš„æ„å›¾æ ‡ç­¾ intention_tag
        # å‘½ä¸­çš„åˆ†æ”¯ï¼›å‘½ä¸­çš„çŸ¥è¯†åº“ç±»å‹ã€idã€åç§° æˆ–è€… å‘½ä¸­çš„æ„å›¾idã€åç§°ï¼›
        # state["message"] = [
        #   {},{},{}, -- å†å²å¯¹è¯
        #   {
        #       "role": "assistant", è§’è‰²
        #       "content": "", å›å¤è¯æœ¯
        #       'intention_tag': '', å›å¤è¯æœ¯æ‰€åœ¨æµç¨‹çš„æ„å‘æ ‡ç­¾
        #       'dialog_id': '', è¯æœ¯id
        #       'logic': {
        #           'user_logic_title':{'ä¸»çº¿æµç¨‹ã€è‚¯å®šã€‘åˆ†æ”¯ â€œè‚¯å®šâ€', 'å¤§æ¨¡å‹ç†è§£ï¼šâ€œå®¢æˆ·è¡¨ç¤ºæƒ³è¦äº†è§£è£…ä¿®â€'},
        #           'assistant_logic_title':'ã€ä¸»çº¿æµç¨‹ã€‘ï¼šä¸»æµç¨‹äºŒä¸šåŠ¡ä»‹ç»ã€è‚¯å®š -> ä¸»çº¿æµç¨‹è·³è½¬ä¸‹ä¸€ä¸»çº¿æµç¨‹',
        #           'detail': [
        #               {'master_id':'ä¸»æµç¨‹id','branch_id':'èŠ‚ç‚¹id', 'hit_branch_id':'å‘½ä¸­çš„åˆ†æ”¯çš„id', 'infer_type': 'æ¨ç†çš„ç±»å‹': '1 æ„å›¾ 2 çŸ¥è¯†åº“', 'infer_use_id':'æ„å›¾/çŸ¥è¯†åº“id', 'infer_use_type': 'çŸ¥è¯†åº“çš„ç±»å‹1é€šç”¨é—®é¢˜ 2ä¸šåŠ¡é—®é¢˜ 3ä¸€èˆ¬é—®é¢˜'},
        #               {'master_id':'ä¸»æµç¨‹id','branch_id':'èŠ‚ç‚¹id', 'hit_branch_id':'å‘½ä¸­çš„åˆ†æ”¯1è‚¯å®š2å¦å®š3æ‹’æ¥4æ— åº”ç­”5é»˜è®¤', 'infer_type': 'æ¨ç†çš„ç±»å‹': '1 æ„å›¾ 2 çŸ¥è¯†åº“', 'infer_use_id':'æ„å›¾/çŸ¥è¯†åº“id', 'infer_use_type': 'çŸ¥è¯†åº“çš„ç±»å‹1é€šç”¨é—®é¢˜ 2ä¸šåŠ¡é—®é¢˜ 3ä¸€èˆ¬é—®é¢˜'}
        #           ]
        #       },
        #   }]
        # state["message"] = [
        #   {},{},{}, -- å†å²å¯¹è¯
        #   {
        #       "role": "assistant", è§’è‰²
        #       "content": "", å›å¤è¯æœ¯
        # state["metadata"] = [
        #   {},{},{}, -- å†å²å¯¹è¯
        #   {
        #       "role": "assistant", è§’è‰²
        #       "content": "", å›å¤è¯æœ¯
        #       'intention_tag': '', å›å¤è¯æœ¯æ‰€åœ¨æµç¨‹çš„æ„å‘æ ‡ç­¾
        #       'dialog_id': '', è¯æœ¯id
        #       'logic': {
        #           'user_logic_title':{'ä¸»çº¿æµç¨‹ã€è‚¯å®šã€‘åˆ†æ”¯ â€œè‚¯å®šâ€', 'å¤§æ¨¡å‹ç†è§£ï¼šâ€œå®¢æˆ·è¡¨ç¤ºæƒ³è¦äº†è§£è£…ä¿®â€'},
        #           'assistant_logic_title':'ã€ä¸»çº¿æµç¨‹ã€‘ï¼šä¸»æµç¨‹äºŒä¸šåŠ¡ä»‹ç»ã€è‚¯å®š -> ä¸»çº¿æµç¨‹è·³è½¬ä¸‹ä¸€ä¸»çº¿æµç¨‹',
        #           'detail': [
        #               {'master_id':'ä¸»æµç¨‹id','branch_id':'èŠ‚ç‚¹id', 'hit_branch_id':'å‘½ä¸­çš„åˆ†æ”¯çš„id', 'infer_type': 'æ¨ç†çš„ç±»å‹': '1 æ„å›¾ 2 çŸ¥è¯†åº“', 'infer_use_id':'æ„å›¾/çŸ¥è¯†åº“id', 'infer_use_type': 'çŸ¥è¯†åº“çš„ç±»å‹1é€šç”¨é—®é¢˜ 2ä¸šåŠ¡é—®é¢˜ 3ä¸€èˆ¬é—®é¢˜'},
        #               {'master_id':'ä¸»æµç¨‹id','branch_id':'èŠ‚ç‚¹id', 'hit_branch_id':'å‘½ä¸­çš„åˆ†æ”¯1è‚¯å®š2å¦å®š3æ‹’æ¥4æ— åº”ç­”5é»˜è®¤', 'infer_type': 'æ¨ç†çš„ç±»å‹': '1 æ„å›¾ 2 çŸ¥è¯†åº“', 'infer_use_id':'æ„å›¾/çŸ¥è¯†åº“id', 'infer_use_type': 'çŸ¥è¯†åº“çš„ç±»å‹1é€šç”¨é—®é¢˜ 2ä¸šåŠ¡é—®é¢˜ 3ä¸€èˆ¬é—®é¢˜'}
        #           ]
        #       },
        #   }]

        # æå–AIå›å¤
        ai_response = ''
        last_msg = state["messages"][-1]
        if last_msg["role"] == "assistant":
            logger_chatflow.info("æ™ºèƒ½å®¢æœï¼š%s", {last_msg['content']})
            ai_response = last_msg["content"]
            print(f"æ™ºèƒ½å®¢æœï¼š{last_msg['content']}")

        return jsonify({
            'success': True,
            # å½“å‰å›å¤çš„è¯æœ¯å†…å®¹
            'response': ai_response,
            # å†å²è®°å½•
            'conversation_history': state["messages"],
            'conversation_history_detail': state["metadata"],
            'call_id': call_id,
            'model_id': actual_used_model,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        logger_chatflow.error(f"ç”Ÿæˆè¯æœ¯å¤±è´¥ - æ¨¡å‹: {actual_used_model}, å‘¼å«: {call_id}, é”™è¯¯: {str(e)}")
        return jsonify({
            'success': False,
            'message': f'è¯æœ¯ç”Ÿæˆå¤±è´¥: {str(e)}'
        }), 500
    finally:
        # é‡Šæ”¾æ¨¡å‹ä½¿ç”¨è®¡æ•°
        if task_id:
            model_manager.release_model(actual_used_model, task_id)


@app.route('/model/destroy', methods=['POST'])
def destroy_model():
    """é”€æ¯æ¨¡å‹æ¥å£"""
    data = request.json
    model_id = data.get('model_id')
    task_id = data.get('task_id')
    force = data.get('force', False)

    if not model_id:
        return jsonify({
            'success': False,
            'message': 'model_id å‚æ•°ä¸èƒ½ä¸ºç©º'
        }), 400

    if model_manager.destroy_model(model_id, force):
        return jsonify({
            'success': True,
            'message': f'æ¨¡å‹ {model_id} é”€æ¯æˆåŠŸ'
        })
    else:
        return jsonify({
            'success': False,
            'message': f'æ¨¡å‹ {model_id} é”€æ¯å¤±è´¥ï¼Œå¯èƒ½ä»æœ‰ä»»åŠ¡åœ¨ä½¿ç”¨'
        }), 400


@app.route('/model/status', methods=['GET'])
def get_model_status():
    """è·å–æ¨¡å‹çŠ¶æ€"""
    model_id = request.args.get('model_id')
    status = model_manager.get_model_status(model_id)
    return jsonify(status)


@app.route('/model/cleanup', methods=['POST'])
def cleanup_models():
    """æ‰‹åŠ¨è§¦å‘æ¸…ç†ç©ºé—²æ¨¡å‹ - ğŸ¯ ä¿®å¤è¿™é‡Œ"""
    data = request.json
    force = data.get('force', False)

    # ğŸ¯ æ ¹æ®forceå‚æ•°å†³å®šæ¸…ç†ç­–ç•¥
    if force:
        result = model_manager.cleanup_idle_models(force_reason='manual')
    else:
        result = model_manager.cleanup_idle_models()  # æ­£å¸¸æ¸…ç†

    status = model_manager.get_model_status()
    return jsonify({
        'success': True,
        'message': 'ç©ºé—²æ¨¡å‹æ¸…ç†å®Œæˆ',
        'cleanup_result': result,  # ğŸ¯ è¿”å›æ¸…ç†è¯¦æƒ…
        'current_stats': {
            'total_models': status['total_models'],
            'active_models': status['active_models'],
            'current_memory_mb': status['current_memory_mb']
        }
    })


@app.route('/model/persistence/backup', methods=['POST'])
def create_manual_backup():
    """æ‰‹åŠ¨åˆ›å»ºæŒä¹…åŒ–æ•°æ®å¤‡ä»½"""
    try:
        if model_manager.create_manual_backup():
            return jsonify({
                'success': True,
                'message': 'æ‰‹åŠ¨å¤‡ä»½åˆ›å»ºæˆåŠŸ'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'æ‰‹åŠ¨å¤‡ä»½åˆ›å»ºå¤±è´¥'
            }), 500
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'åˆ›å»ºå¤‡ä»½å¼‚å¸¸: {str(e)}'
        }), 500


@app.route('/model/persistence/status', methods=['GET'])
def get_persistence_status():
    """è·å–æŒä¹…åŒ–çŠ¶æ€"""
    try:
        disk_info = model_manager.persistence_manager.get_disk_usage()
        models_count = len([f for f in os.listdir(model_manager.persistence_manager.models_dir)
                            if f.endswith('.json')])
        backups_count = len([f for f in os.listdir(model_manager.persistence_manager.backup_dir)
                             if f.endswith('.json')])

        return jsonify({
            'success': True,
            'persistence_path': model_manager.persistence_manager.base_path,
            'models_persisted': models_count,
            'backups_count': backups_count,
            'disk_usage': disk_info,
            'warnings': ['ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜'] if disk_info.get('usage_percent', 0) > 90 else []
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–æŒä¹…åŒ–çŠ¶æ€å¤±è´¥: {str(e)}'
        }), 500


def start_dynamic_service(port=5002):
    """å¯åŠ¨åŠ¨æ€æ¨¡å‹æœåŠ¡"""
    logger_chatflow.info(f"å¯åŠ¨åŠ¨æ€AIæ¨¡å‹æœåŠ¡ï¼Œç«¯å£: {port}")
    logger_chatflow.info("æœåŠ¡ç‰¹ç‚¹: åŠ¨æ€æ¨¡å‹ç®¡ç†ï¼ŒæŒ‰éœ€åˆ›å»ºï¼Œè‡ªåŠ¨æ¸…ç†")

    app.run(host='0.0.0.0', port=port, debug=False, threaded=True)


if __name__ == '__main__':
    start_dynamic_service()

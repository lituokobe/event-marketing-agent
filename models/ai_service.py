# Standard library imports
import asyncio
import json
import logging
import os
import sys
import threading
import time
import traceback
from collections import defaultdict
from datetime import datetime

# Third-party imports
import psutil
import requests
from quart import Quart, request, jsonify
import redis.asyncio as redis_async

# LangChain / LangGraph ecosystem
from langchain_core.messages import HumanMessage
from langgraph.checkpoint.redis import AsyncRedisSaver

# Internal / project-specific imports
from agent_builders.chatflow_builder import build_chatflow
from config.config_setup import ChatFlowConfig
from config.setting import settings
from data.simulated_data_lt_simplified import (
    agent_data,
    knowledge,
    knowledge_main_flow,
    chatflow_design,
    global_configs,
    intentions,
)
from functionals.log_utils import logger_chatflow
from functionals.matchers import KeywordMatcher
from models.async_notification_manager import AsyncNotificationManager
from models.persistence_manager import ModelPersistenceManager

# ASGI server imports (Hypercorn)
from hypercorn.config import Config
from hypercorn.asyncio import serve

# TODO: Start the app
app = Quart(__name__)

PHP_CALLBACK_URL = settings.PHP_CALLBACK_URL  # PHPå›è°ƒåœ°å€

# TODO åˆ›å»ºå…¨å±€åŠ¨æ€æ¨¡å‹ç®¡ç†å™¨
class DynamicModelManager:
    def __init__(self):
        self.models = {}  # {model_id: model_data}
        self.model_usage = defaultdict(int)  # æ¨¡å‹ä½¿ç”¨è®¡æ•°
        self.model_last_used = {}  # æ¨¡å‹æœ€åä½¿ç”¨æ—¶é—´
        self.model_tasks = defaultdict(set)  # æ¨¡å‹å…³è”çš„ä»»åŠ¡
        self.model_created_time = {}  # ğŸ¯ è®°å½•æ¨¡å‹åˆ›å»ºæ—¶é—´
        self.lock = threading.RLock()

        # ğŸ¯ æŒä¹…åŒ–ç®¡ç†å™¨
        self.persistence_manager = ModelPersistenceManager()
        # å¼‚æ­¥é€šçŸ¥ç®¡ç†å™¨
        self.notification_manager = AsyncNotificationManager(max_workers=5)

        # èµ„æºé…ç½®
        self.max_models = 50
        self.max_memory_mb = 4096  # ğŸ¯ æ–°å¢ï¼šæœ€å¤§å†…å­˜é™åˆ¶ 2GB
        self.model_timeout = 3600
        self.cleanup_interval = 300
        self.model_memory_estimate = 100  # ğŸ¯ æ¯ä¸ªæ¨¡å‹é¢„ä¼°å†…å­˜å ç”¨(MB)

    def start_cleanup_task(self):
        """å¯åŠ¨åå°æ¸…ç†çº¿ç¨‹"""
        async def cleanup_worker():
            while True:
                await asyncio.sleep(self.cleanup_interval)
                try:
                    # ğŸ¯ å…ˆæ£€æŸ¥æ˜¯å¦éœ€è¦ç´§æ€¥æ¸…ç†
                    emergency_result = await self.check_and_cleanup_if_needed()
                    if emergency_result.get('cleaned', False):
                        logger_chatflow.debug(f"ğŸ”„ ç´§æ€¥æ¸…ç†å®Œæˆ: {emergency_result}")

                    # ğŸ¯ ç„¶åè¿›è¡Œå¸¸è§„æ¸…ç†
                    normal_result = await self.cleanup_idle_models()  # æ­£å¸¸æ¸…ç†
                    if normal_result['removed_count'] > 0:
                        logger_chatflow.debug(f"ğŸ”„ å¸¸è§„æ¸…ç†å®Œæˆ: ç§»é™¤äº† {normal_result['removed_count']} ä¸ªæ¨¡å‹")

                except Exception as e:
                    logger_chatflow.error(f"æ¸…ç†çº¿ç¨‹å¼‚å¸¸: {str(e)}")

        asyncio.create_task(cleanup_worker())

    def _notify_php_model_activated(self, model_id):
        """å¼‚æ­¥é€šçŸ¥PHPæ¨¡å‹æ¿€æ´»"""
        try:
            payload = {
                'model_id': model_id,
                'status': 'activated',
                'timestamp': datetime.now().isoformat()
            }
            # ä½¿ç”¨å¼‚æ­¥çº¿ç¨‹
            thread = threading.Thread(
                target=lambda: requests.post(f"{PHP_CALLBACK_URL}", json=payload, timeout=3),
                daemon=True
            )
            thread.start()
            logger_chatflow.info(f"ğŸ“¤ å¼‚æ­¥é€šçŸ¥PHPæ¨¡å‹æ¿€æ´»: {model_id}")
        except Exception as e:
            logger_chatflow.error(f"âŒ å¼‚æ­¥é€šçŸ¥PHPæ¨¡å‹æ¿€æ´»å¤±è´¥: {str(e)}")

    def _notify_php_model_activation_failed(self, model_id, error_msg):
        """é€šçŸ¥PHPæ¨¡å‹æ¿€æ´»å¤±è´¥"""
        try:
            payload = {
                'model_id': model_id,
                'status': 'sleep',  # å›é€€åˆ°ä¼‘çœ çŠ¶æ€
                'timestamp': datetime.now().isoformat(),
                'reason': f'activation_failed: {error_msg}'
            }
            # ä½¿ç”¨å¼‚æ­¥çº¿ç¨‹å‘é€é€šçŸ¥
            thread = threading.Thread(
                target=lambda: requests.post(f"{PHP_CALLBACK_URL}", json=payload, timeout=3),
                daemon=True
            )
            thread.start()
            logger_chatflow.info(f"ğŸ“¤ é€šçŸ¥PHPæ¨¡å‹æ¿€æ´»å¤±è´¥: {model_id}, åŸå› : {error_msg}")
        except Exception as e:
            logger_chatflow.error(f"âŒ é€šçŸ¥PHPæ¨¡å‹æ¿€æ´»å¤±è´¥å¤±è´¥: {str(e)}")

    def _notify_php_model_sleep(self, model_id):
        """å¼‚æ­¥é€šçŸ¥PHPæ¨¡å‹ä¼‘çœ """
        payload = {
            'model_id': model_id,
            'status': 'sleep',
            'timestamp': datetime.now().isoformat(),
            'reason': 'no_active_tasks_or_expired'
        }
        self.notification_manager.add_notification(
            f"{PHP_CALLBACK_URL}",
            payload,
            "model_sleep"
        )

    def notify_php_task_pause(self, task_id, model_id, reason):
        """å¼‚æ­¥é€šçŸ¥PHPæš‚åœä»»åŠ¡"""
        try:
            payload = {
                'task_id': task_id,
                'model_id': model_id,
                'status': 'pause_task',
                'reason': reason,
                'timestamp': datetime.now().isoformat()
            }
            # ä½¿ç”¨å¼‚æ­¥çº¿ç¨‹
            thread = threading.Thread(
                target=lambda: requests.post(f"{PHP_CALLBACK_URL}", json=payload, timeout=3),
                daemon=True
            )
            thread.start()
            logger_chatflow.warning(f"ğŸ“¤ å¼‚æ­¥é€šçŸ¥PHPæš‚åœä»»åŠ¡: {task_id}, åŸå› : {reason}")
        except Exception as e:
            logger_chatflow.error(f"âŒ å¼‚æ­¥é€šçŸ¥PHPæš‚åœä»»åŠ¡å¤±è´¥: {str(e)}")


    async def recover_models_on_startup(self):
        """æœåŠ¡å¯åŠ¨æ—¶æ¢å¤æ¨¡å‹ - ç®€åŒ–ç‰ˆæœ¬"""
        logger_chatflow.info("ğŸ”„ å¼€å§‹æ¢å¤æŒä¹…åŒ–çš„æ¨¡å‹...")

        # åŠ è½½æ¨¡å‹é…ç½®
        model_configs = self.persistence_manager.load_model_configs()
        recovered_count = 0
        expired_count = 0

        for model_id, config_data in model_configs.items():
            try:
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿‡æœŸ
                current_time = time.time()
                expire_time = config_data.get('expire_time', 0)

                if current_time > expire_time:
                    logger_chatflow.info(f"ğŸ—‘ï¸ è·³è¿‡è¿‡æœŸæ¨¡å‹å¹¶åˆ é™¤é…ç½®: {model_id}")
                    self.persistence_manager.delete_model_config(model_id)
                    expired_count += 1
                    continue

                # é‡æ–°åˆå§‹åŒ–æ¨¡å‹
                chatflow_config = self._build_chatflow_config(config_data.get('config', {}))

                redis_client = redis_async.Redis(  # å¼‚æ­¥Redis
                    host=settings.REDIS_SERVER,
                    password=settings.REDIS_PASSWORD,
                    port=int(settings.REDIS_PORT),
                    db=settings.REDIS_DB,  # Redis Search requires index be built on database 0
                    decode_responses=False,
                    # Let Redis reserve the binary data, instead converting it to Python strings
                    max_connections=50
                )
                redis_checkpointer = AsyncRedisSaver(redis_client=redis_client)
                await redis_checkpointer.setup()  # Async setup
                chatflow, milvus_client = await build_chatflow(chatflow_config, redis_checkpointer=redis_checkpointer)
                logger_chatflow.info("âœ… build_chatflow completed!")
                # æ¢å¤æ¨¡å‹æ•°æ®
                self.models[model_id] = {
                    'instance': chatflow,
                    'config': config_data.get('config', {}),
                    'created_time': config_data.get('created_time', datetime.now()),
                    'expire_time': expire_time,
                    'memory_usage': config_data.get('memory_usage', 0),
                    'status': 'recovered'
                }

                # æ¢å¤ä½¿ç”¨ç»Ÿè®¡ï¼ˆé‡ç½®ä¸º0ï¼Œå› ä¸ºæœåŠ¡é‡å¯ï¼‰
                self.model_usage[model_id] = 0
                self.model_last_used[model_id] = config_data.get('last_used', datetime.now())
                self.model_created_time[model_id] = config_data.get('created_time', datetime.now())

                recovered_count += 1
                logger_chatflow.info(f"âœ… æ¢å¤æ¨¡å‹æˆåŠŸ: {model_id}")

            except Exception as e:
                logger_chatflow.error(f"âŒ æ¢å¤æ¨¡å‹å¤±è´¥ {model_id}: {str(e)}")
                continue

        logger_chatflow.info(f"ğŸ‰ æ¨¡å‹æ¢å¤å®Œæˆ: æˆåŠŸ {recovered_count} ä¸ª, è¿‡æœŸ {expired_count} ä¸ª")

    async def initialize_model(self, model_id, config_data=None, task_id=None, expire_time=None):
        """åŠ¨æ€åˆå§‹åŒ–æ¨¡å‹"""
        with self.lock:
            # æ£€æŸ¥æ˜¯å¦å·²è¾¾æ¨¡å‹ä¸Šé™
            if len(self.models) >= self.max_models:
                # å°è¯•æ¸…ç†ç©ºé—²æ¨¡å‹
                await self.cleanup_idle_models(force_reason='count_exceed')
                if len(self.models) >= self.max_models:
                    error_msg = f"æ¨¡å‹æ•°é‡å·²è¾¾ä¸Šé™ {self.max_models}ï¼Œæ— æ³•åˆ›å»ºæ–°æ¨¡å‹"
                    self._notify_php_model_activation_failed(model_id, error_msg)
                    raise Exception(error_msg)

            # å¦‚æœæ¨¡å‹å·²å­˜åœ¨ï¼Œå¢åŠ ä½¿ç”¨è®¡æ•°
            if model_id in self.models:
                self.model_usage[model_id] += 1
                if task_id:
                    self.model_tasks[model_id].add(task_id)
                if expire_time:
                    self.models[model_id]['expire_time'] = expire_time
                logger_chatflow.info(f"æ¨¡å‹ {model_id} å·²å­˜åœ¨ï¼Œå¢åŠ ä½¿ç”¨è®¡æ•°: {self.model_usage[model_id]}")
                return True

            try:
                logger_chatflow.info(f"å¼€å§‹åŠ¨æ€åˆå§‹åŒ–æ¨¡å‹: {model_id}")

                # æ„å»ºé…ç½®
                chatflow_config = self._build_chatflow_config(config_data)

                redis_client = redis_async.Redis(  # å¼‚æ­¥Redis
                    host=settings.REDIS_SERVER,
                    password=settings.REDIS_PASSWORD,
                    port=int(settings.REDIS_PORT),
                    db=settings.REDIS_DB,  # Redis Search requires index be built on database 0
                    decode_responses=False,
                    # Let Redis reserve the binary data, instead converting it to Python strings
                    max_connections=50
                )
                redis_checkpointer = AsyncRedisSaver(redis_client=redis_client)
                await redis_checkpointer.setup()  # Async setup
                
                chatflow, milvus_client = await build_chatflow(chatflow_config, redis_checkpointer=redis_checkpointer)
                
                # å­˜å‚¨æ¨¡å‹å®ä¾‹
                current_time = datetime.now()
                self.models[model_id] = {
                    'instance': chatflow,
                    'milvus_client': milvus_client,
                    'redis_client': redis_client,
                    'config': config_data or {},
                    'created_time': current_time,
                    'expire_time': expire_time or (time.time() + 14 * 24 * 3600),
                    'memory_usage': self._get_memory_usage(),
                    'status': 'active'
                }
                self.model_usage[model_id] = 0  # ğŸ¯ ä¿®æ”¹ï¼šæ–°æ¨¡å‹åˆå§‹è®¡æ•°ä¸º0
                self.model_last_used[model_id] = current_time
                self.model_created_time[model_id] = current_time

                if task_id:
                    self.model_tasks[model_id].add(task_id)
                    self.model_usage[model_id] += 1  # ğŸ¯ å¦‚æœæœ‰task_idï¼Œæ‰å¢åŠ è®¡æ•°

                logger_chatflow.info(f"æ¨¡å‹ {model_id} åŠ¨æ€åˆå§‹åŒ–æˆåŠŸï¼Œå½“å‰æ¨¡å‹æ€»æ•°: {len(self.models)}")

                # ğŸ¯ æŒä¹…åŒ–æ¨¡å‹é…ç½®
                model_persist_data = {
                    'config': config_data or {},
                    'created_time': current_time,
                    'expire_time': expire_time or (time.time() + 14 * 24 * 3600),
                    'memory_usage': self._get_memory_usage(),
                    'status': 'active',
                    'last_used': current_time
                }
                self.persistence_manager.save_model_config(model_id, model_persist_data)

                # é€šçŸ¥PHPæ¨¡å‹æ¿€æ´»
                self._notify_php_model_activated(model_id)
                return True

            except Exception as e:
                logger_chatflow.error(f"æ¨¡å‹ {model_id} åŠ¨æ€åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                # æ¸…ç†å¯èƒ½çš„éƒ¨åˆ†åˆå§‹åŒ–
                if model_id in self.models:
                    del self.models[model_id]
                if model_id in self.model_usage:
                    del self.model_usage[model_id]
                # é€šçŸ¥PHPæ¿€æ´»å¤±è´¥
                self._notify_php_model_activation_failed(model_id, str(e))
                raise

    def get_model(self, model_id, task_id=None):
        """è·å–æ¨¡å‹å®ä¾‹ï¼Œæ›´æ–°ä½¿ç”¨æ—¶é—´"""
        with self.lock:
            if model_id in self.models:
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿‡æœŸ
                if self._check_model_expired(model_id):
                    logger_chatflow.warning(f"æ¨¡å‹ {model_id} å·²è¿‡æœŸ")
                    # é€šçŸ¥PHPæ¨¡å‹ä¼‘çœ     è¿™æ­¥å’Œä¸‹é¢çš„ æš‚åœå¹¶é‡æ–°æ¿€æ´»é‡å¤ notify_php_task_pause
                    # self._notify_php_model_sleep(model_id)
                    return None

                self.model_last_used[model_id] = datetime.now()
                self.model_usage[model_id] += 1
                if task_id and task_id not in self.model_tasks[model_id]:
                    self.model_tasks[model_id].add(task_id)
                return self.models[model_id]['instance']
            return None

    def _check_model_expired(self, model_id):
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿‡æœŸ"""
        if model_id in self.models:
            model_data = self.models[model_id]
            current_time = time.time()
            if current_time > model_data['expire_time']:
                return True
        return False

    def extend_model_expire_time(self, model_id, expire_time):
        """å»¶é•¿æ¨¡å‹è¿‡æœŸæ—¶é—´"""
        with self.lock:
            if model_id in self.models:
                self.models[model_id]['expire_time'] = expire_time
                logger_chatflow.info(f"æ¨¡å‹ {model_id} è¿‡æœŸæ—¶é—´å·²å»¶é•¿è‡³: {expire_time}")
                return True
            return False

    def release_model(self, model_id, task_id=None):
        """é‡Šæ”¾æ¨¡å‹ä½¿ç”¨è®¡æ•°"""
        with self.lock:
            if model_id in self.model_usage:
                self.model_usage[model_id] = max(0, self.model_usage[model_id] - 1)

                # å¦‚æœæŒ‡å®šäº†task_idï¼Œä»ä»»åŠ¡åˆ—è¡¨ä¸­ç§»é™¤
                if task_id and task_id in self.model_tasks[model_id]:
                    self.model_tasks[model_id].remove(task_id)

                logger_chatflow.info(f"é‡Šæ”¾æ¨¡å‹ {model_id} ä½¿ç”¨è®¡æ•°ï¼Œå½“å‰: {self.model_usage[model_id]}")

    async def destroy_model(self, model_id, force=False):
        """é”€æ¯æ¨¡å‹å®ä¾‹"""
        with self.lock:
            if model_id not in self.models:
                return True

            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä»»åŠ¡åœ¨ä½¿ç”¨
            if not force and self.model_usage[model_id] > 0:
                logger_chatflow.warning(f"æ¨¡å‹ {model_id} ä»æœ‰ {self.model_usage[model_id]} ä¸ªä»»åŠ¡åœ¨ä½¿ç”¨ï¼Œæ— æ³•é”€æ¯")
                return False

            try:
                # æ¸…ç†æ¨¡å‹èµ„æº
                model_data = self.models[model_id]
                milvus_client = model_data.get('milvus_client')
                redis_client = model_data.get('redis_client')
                # Close Milvus
                if milvus_client:
                    try:
                        await milvus_client.close()
                        logger_chatflow.info(f"âœ… Milvus client closed for model {model_id}")
                    except Exception as e:
                        logger_chatflow.error(f"âŒ Failed to close Milvus client for {model_id}: {e}")

                # Close Redis
                if redis_client:
                    try:
                        await redis_client.aclose()
                        logger_chatflow.info(f"âœ… Redis client closed for model {model_id}")
                    except Exception as e:
                        logger_chatflow.error(f"âŒ Failed to close Redis client for {model_id}: {e}")

                # ä»ç®¡ç†å™¨ä¸­ç§»é™¤
                del self.models[model_id]
                if model_id in self.model_usage:
                    del self.model_usage[model_id]
                if model_id in self.model_last_used:
                    del self.model_last_used[model_id]
                if model_id in self.model_tasks:
                    del self.model_tasks[model_id]

                # ğŸ¯ åˆ é™¤æŒä¹…åŒ–é…ç½®ï¼ˆä¼šè‡ªåŠ¨æ¸…ç†æ—§å¤‡ä»½ï¼‰
                self.persistence_manager.delete_model_config(model_id)

                logger_chatflow.info(f"æ¨¡å‹ {model_id} å·²é”€æ¯ï¼Œå‰©ä½™æ¨¡å‹æ•°: {len(self.models)}")

                # é€šçŸ¥PHPæ¨¡å‹ä¼‘çœ 
                self._notify_php_model_sleep(model_id)
                return True

            except Exception as e:
                logger_chatflow.error(f"é”€æ¯æ¨¡å‹ {model_id} å¤±è´¥: {str(e)}")
                return False

    def again_model(self, model_id):
        """é‡å¯æ¨¡å‹å®ä¾‹"""
        with self.lock:
            if model_id not in self.models:
                return True

            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä»»åŠ¡åœ¨ä½¿ç”¨
            print(self.model_usage[model_id])
            
            try:
                # æ¸…ç†æ¨¡å‹èµ„æº
                model_data = self.models[model_id]

                # ä»ç®¡ç†å™¨ä¸­ç§»é™¤
                del self.models[model_id]
                if model_id in self.model_usage:
                    del self.model_usage[model_id]
                if model_id in self.model_last_used:
                    del self.model_last_used[model_id]
                if model_id in self.model_tasks:
                    del self.model_tasks[model_id]

                # ğŸ¯ åˆ é™¤æŒä¹…åŒ–é…ç½®ï¼ˆä¼šè‡ªåŠ¨æ¸…ç†æ—§å¤‡ä»½ï¼‰
                self.persistence_manager.delete_model_config(model_id)

                logger_chatflow.info(f"æ¨¡å‹ {model_id} å·²é”€æ¯ï¼Œå‰©ä½™æ¨¡å‹æ•°: {len(self.models)}")

                
                return True

            except Exception as e:
                logger_chatflow.error(f"é”€æ¯æ¨¡å‹ {model_id} å¤±è´¥: {str(e)}")
                return False
    async def cleanup_idle_models(self, force_reason=None):
        """æ™ºèƒ½æ¸…ç†ç©ºé—²æ¨¡å‹
        Args:
            force_reason: å¼ºåˆ¶æ¸…ç†åŸå›  - 'count_exceed', 'memory_exceed', 'manual'
        """
        with self.lock:
            current_time = datetime.now()
            current_timestamp = time.time()  # ğŸ¯ è·å–å½“å‰æ—¶é—´æˆ³ç”¨äºè¿‡æœŸæ£€æŸ¥
            current_memory = self._get_memory_usage()
            total_models = len(self.models)

            # ğŸ¯ æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
            stats = {
                'total_models': total_models,
                'active_models': len([m for m in self.models if self.model_usage[m] > 0]),
                'idle_models': len([m for m in self.models if self.model_usage[m] == 0]),
                'current_memory_mb': current_memory,
                'max_memory_mb': self.max_memory_mb,
                'max_models': self.max_models,
                'force_reason': force_reason
            }

            logger_chatflow.info(f"ğŸ“Š æ¸…ç†å‰çŠ¶æ€: æ¨¡å‹æ€»æ•°={stats['total_models']}, "
                                 f"æ´»è·ƒ={stats['active_models']}, ç©ºé—²={stats['idle_models']}, "
                                 f"å†…å­˜={stats['current_memory_mb']:.1f}MB")

            # ğŸ¯ æŒ‰åˆ›å»ºæ—¶é—´æ’åºçš„ç©ºé—²æ¨¡å‹åˆ—è¡¨ï¼ˆæœ€è€çš„åœ¨å‰ï¼‰
            idle_models = []
            for model_id in self.models:
                if self.model_usage[model_id] == 0:  # åªè€ƒè™‘ç©ºé—²æ¨¡å‹
                    idle_time = (current_time - self.model_last_used[model_id]).total_seconds()
                    created_time = self.model_created_time[model_id]
                    model_data = self.models[model_id]

                    # ğŸ¯ æ£€æŸ¥æ˜¯å¦ç»å¯¹è¿‡æœŸ
                    expired = current_timestamp > model_data['expire_time']

                    idle_models.append({
                        'model_id': model_id,
                        'created_time': created_time,
                        'idle_time': idle_time,
                        'last_used': self.model_last_used[model_id],
                        'expired': expired,  # ğŸ¯ æ–°å¢ï¼šæ˜¯å¦å·²è¿‡æœŸ
                        'expire_time': model_data['expire_time'],
                        'expire_in_hours': max(0, (model_data['expire_time'] - current_timestamp) / 3600)
                    })

            # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆæœ€è€çš„åœ¨å‰ï¼‰
            idle_models.sort(key=lambda x: x['created_time'])

            models_to_remove = []
            removal_reason = "normal_timeout"

            # ğŸ¯ æ™ºèƒ½æ¸…ç†å†³ç­–
            if force_reason == 'count_exceed':
                # æ¨¡å‹æ•°é‡è¶…é™ï¼šæ¸…ç†æœ€è€çš„ç©ºé—²æ¨¡å‹ï¼Œç›´åˆ°æ•°é‡è¾¾æ ‡
                target_count = max(1, self.max_models - 5)  # æ¸…ç†åˆ°æ¯”ä¸Šé™å°‘5ä¸ªï¼Œç•™å‡ºç¼“å†²
                excess_count = total_models - target_count

                if excess_count > 0 and idle_models:
                    models_to_remove = idle_models[:min(excess_count, len(idle_models))]
                    removal_reason = f"count_exceed_{excess_count}_over"

            elif force_reason == 'memory_exceed':
                # å†…å­˜è¶…é™ï¼šæ¸…ç†æœ€è€çš„ç©ºé—²æ¨¡å‹ï¼Œç›´åˆ°å†…å­˜è¾¾æ ‡
                target_memory = self.max_memory_mb * 0.8  # æ¸…ç†åˆ°80%çš„å†…å­˜ä½¿ç”¨
                excess_memory = current_memory - target_memory

                if excess_memory > 0 and idle_models:
                    # é¢„ä¼°æ¸…ç†æ•ˆæœï¼šæ¯ä¸ªæ¨¡å‹çº¦é‡Šæ”¾100MB
                    models_needed = min(len(idle_models), int(excess_memory / self.model_memory_estimate) + 1)
                    models_to_remove = idle_models[:models_needed]
                    removal_reason = f"memory_exceed_{excess_memory:.0f}MB_over"

            elif force_reason == 'manual':
                # ğŸ¯ æ‰‹åŠ¨æ¸…ç†ï¼šæ¸…ç†æ‰€æœ‰è¶…æ—¶ç©ºé—²æ¨¡å‹å’Œå·²è¿‡æœŸæ¨¡å‹
                for model_info in idle_models:
                    if model_info['idle_time'] > self.model_timeout and model_info['expired']:
                        models_to_remove.append(model_info)
                removal_reason = "manual_cleanup"

            else:
                # ğŸ¯ æ­£å¸¸æ¸…ç†ï¼šæ¸…ç†è¶…æ—¶ç©ºé—²æ¨¡å‹å’Œå·²è¿‡æœŸæ¨¡å‹
                for model_info in idle_models:
                    if model_info['idle_time'] > self.model_timeout and model_info['expired']:
                        models_to_remove.append(model_info)
                removal_reason = "normal_expired"

            # ğŸ¯ æ‰§è¡Œæ¸…ç†
            removed_count = 0
            for model_info in models_to_remove:
                model_id = model_info['model_id']
                if await self.destroy_model(model_id, force=True):
                    removed_count += 1
                    if model_info['expired']:
                        expired_status = "å·²è¿‡æœŸ"
                    else:
                        expire_hours = model_info.get('expire_in_hours', 0)
                        if expire_hours > 24:
                            expired_status = f"æœªè¿‡æœŸ(è¿˜æœ‰{expire_hours / 24:.1f}å¤©)"
                        elif expire_hours > 1:
                            expired_status = f"æœªè¿‡æœŸ(è¿˜æœ‰{expire_hours:.1f}å°æ—¶)"
                        else:
                            expired_status = f"æœªè¿‡æœŸ(è¿˜æœ‰{expire_hours * 60:.0f}åˆ†é’Ÿ)"

                    logger_chatflow.info(f"ğŸ§¹ æ¸…ç†æ¨¡å‹: {model_id}, "
                                         f"åˆ›å»ºæ—¶é—´: {model_info['created_time'].strftime('%Y-%m-%d %H:%M:%S')}, "
                                         f"ç©ºé—²: {model_info['idle_time']:.0f}ç§’, "
                                         f"è¿‡æœŸçŠ¶æ€: {expired_status}, "
                                         f"åŸå› : {removal_reason}")

            # ğŸ¯ æ¸…ç†åç»Ÿè®¡
            if removed_count > 0:
                after_memory = self._get_memory_usage()
                memory_saved = current_memory - after_memory
                logger_chatflow.info(f"âœ… æ¸…ç†å®Œæˆ: ç§»é™¤äº† {removed_count} ä¸ªæ¨¡å‹, "
                                     f"é‡Šæ”¾å†…å­˜: {memory_saved:.1f}MB, "
                                     f"å‰©ä½™æ¨¡å‹: {len(self.models)}")

                # ğŸ¯ è®°å½•æ¸…ç†æ•ˆæœæ•°æ®ï¼ˆç”¨äºä¼˜åŒ–é…ç½®ï¼‰
                self._record_cleanup_stats({
                    'before_memory': current_memory,
                    'after_memory': after_memory,
                    'memory_saved': memory_saved,
                    'models_removed': removed_count,
                    'reason': removal_reason,
                    'timestamp': datetime.now().isoformat()
                })

            return {
                'removed_count': removed_count,
                'reason': removal_reason,
                'stats_before': stats,
                'stats_after': {
                    'total_models': len(self.models),
                    'current_memory_mb': self._get_memory_usage()
                }
            }

    async def check_and_cleanup_if_needed(self):
        """æ£€æŸ¥å¹¶è§¦å‘å¿…è¦çš„æ¸…ç† - ğŸ¯ ç¡®ä¿è¿™ä¸ªæ–¹æ³•è¢«æ­£ç¡®è°ƒç”¨"""
        current_memory = self._get_memory_usage()
        total_models = len(self.models)

        force_reason = None

        # ğŸ¯ å†…å­˜è¶…é™æ£€æŸ¥
        if current_memory > self.max_memory_mb:
            logger_chatflow.warning(f"ğŸš¨ å†…å­˜è¶…é™: {current_memory:.1f}MB > {self.max_memory_mb}MB")
            force_reason = 'memory_exceed'

        # ğŸ¯ æ¨¡å‹æ•°é‡è¶…é™æ£€æŸ¥
        elif total_models > self.max_models:
            logger_chatflow.warning(f"âš ï¸ æ¨¡å‹æ•°é‡è¶…é™: {total_models} > {self.max_models}")
            force_reason = 'count_exceed'

        if force_reason:
            return await self.cleanup_idle_models(force_reason=force_reason)

        return {'cleaned': False, 'reason': 'not_needed'}

    def _record_cleanup_stats(self, stats):
        """è®°å½•æ¸…ç†ç»Ÿè®¡ä¿¡æ¯ï¼Œç”¨äºä¼˜åŒ–é…ç½®"""
        # è¿™é‡Œå¯ä»¥å­˜å‚¨åˆ°æ–‡ä»¶æˆ–æ•°æ®åº“ï¼Œç”¨äºåˆ†æå†…å­˜ä½¿ç”¨æ¨¡å¼
        logger_chatflow.debug(f"ğŸ“ˆ æ¸…ç†ç»Ÿè®¡: {json.dumps(stats, default=str)}")

    @staticmethod
    def _build_chatflow_config(config_data):
        print(f"æ¨¡å‹é…ç½®æ•°æ®ï¼š{str(config_data)[:800]}......")
        # æ£€æŸ¥é…ç½®æ•°æ®æ˜¯å¦å®Œæ•´
        required_keys = [
            'agent_data',
            'intentions',
            'knowledge',
            'chatflow_design',
            'knowledge_main_flow',
            'global_configs'
        ]

        # æ£€æŸ¥config_dataæ˜¯å¦å­˜åœ¨ä¸”åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ
        has_all_required = (
                config_data and
                isinstance(config_data, dict) and
                all(key in config_data for key in required_keys)
        )

        if has_all_required:
            # å¯ä»¥æ·»åŠ æ›´è¯¦ç»†çš„æ£€æŸ¥ï¼Œæ¯”å¦‚å€¼æ˜¯å¦ä¸ä¸ºç©º
            # æ£€æŸ¥å€¼æ˜¯å¦æœ‰æ•ˆï¼ˆéNoneä¸”ä¸æ˜¯ç©ºå­—ç¬¦ä¸²/åˆ—è¡¨/å­—å…¸ï¼‰
            values_valid = all(
                config_data.get(key) not in (None, '', [], {})
                for key in required_keys
            )

            if not values_valid:
                # è®°å½•å“ªäº›å­—æ®µæœ‰é—®é¢˜
                missing_or_empty = [
                    key for key in required_keys
                    if config_data.get(key) in (None, '', [], {})
                ]
                print(f"è­¦å‘Š: ä»¥ä¸‹é…ç½®å­—æ®µä¸ºç©ºæˆ–æ— æ•ˆ: {missing_or_empty}")
                # å¯ä»¥é€‰æ‹©å›é€€åˆ°é»˜è®¤é…ç½®æˆ–æŠ›å‡ºå¼‚å¸¸
                # return None  # æˆ–æŠ›å‡ºå¼‚å¸¸

            print("ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ•°æ®")
            print(f"é…ç½®å­—æ®µ: {list(config_data.keys())}")

            # æµ‹è¯•å…ˆç”¨é»˜è®¤çš„ åˆ°æ—¶å€™æ”¹æˆå®é™…çš„
            chatflow_config = ChatFlowConfig.from_files(
                config_data.get('agent_data'),
                config_data.get('knowledge'),
                config_data.get('knowledge_main_flow'),
                config_data.get('chatflow_design'),
                config_data.get('global_configs'),
                config_data.get('intentions'),
            )

        else:
            # å¦‚æœé…ç½®ä¸å®Œæ•´ï¼Œè®°å½•ç¼ºå¤±çš„å­—æ®µ
            if config_data and isinstance(config_data, dict):
                missing_keys = [key for key in required_keys if key not in config_data]
                print(f"é…ç½®æ•°æ®ä¸å®Œæ•´ï¼Œç¼ºå¤±å­—æ®µ: {missing_keys}")
                print(f"å·²æœ‰å­—æ®µ: {list(config_data.keys())}")
            else:
                print("é…ç½®æ•°æ®ä¸ºç©ºæˆ–ä¸æ˜¯å­—å…¸ç±»å‹")

            print("å›é€€åˆ°ä½¿ç”¨é»˜è®¤è·¯å¾„é…ç½®")

            # ä½¿ç”¨é»˜è®¤è·¯å¾„é…ç½®
            chatflow_config = ChatFlowConfig.from_files(
                agent_data,
                knowledge,
                knowledge_main_flow,
                chatflow_design,
                global_configs,
                intentions
            )

        return chatflow_config

    def get_model_status(self, model_id=None):
        """è·å–æ¨¡å‹çŠ¶æ€ - ä¿®å¤JSONåºåˆ—åŒ–é—®é¢˜"""
        with self.lock:
            current_memory = self._get_memory_usage()
            if model_id:
                if model_id in self.models:
                    model_data = self.models[model_id]
                    # ğŸ¯ ä¿®å¤ï¼šå°† set è½¬æ¢ä¸º list ä»¥ä¾¿ JSON åºåˆ—åŒ–
                    associated_tasks = list(self.model_tasks[model_id]) if model_id in self.model_tasks else []

                    return {
                        'model_id': model_id,
                        'status': 'active',
                        'created_time': model_data['created_time'].isoformat(),
                        'last_used': self.model_last_used[model_id].isoformat(),
                        'usage_count': self.model_usage[model_id],
                        'associated_tasks': associated_tasks,  # ğŸ¯ ä½¿ç”¨ list è€Œä¸æ˜¯ set
                        'memory_usage': model_data['memory_usage']
                    }
                else:
                    return {'model_id': model_id, 'status': 'not_found'}
            else:
                # å…¨å±€çŠ¶æ€ - å¢å¼ºä¿¡æ¯
                idle_models = [m for m in self.models if self.model_usage[m] == 0]
                active_models = [m for m in self.models if self.model_usage[m] > 0]

                # è®¡ç®—å†…å­˜ä½¿ç”¨ç»Ÿè®¡
                total_estimated_memory = len(self.models) * self.model_memory_estimate

                # ğŸ¯ ä¿®å¤ï¼šæ„å»ºå¯åºåˆ—åŒ–çš„æ¨¡å‹çŠ¶æ€å­—å…¸
                models_status = {}
                for model_id, data in self.models.items():
                    # ğŸ¯ ä¿®å¤ï¼šå°† set è½¬æ¢ä¸º list
                    associated_tasks_list = list(self.model_tasks[model_id]) if model_id in self.model_tasks else []

                    models_status[model_id] = {
                        'created_time': data['created_time'].isoformat(),
                        'last_used': self.model_last_used[model_id].isoformat(),
                        'usage_count': self.model_usage[model_id],
                        'associated_tasks': associated_tasks_list,  # ğŸ¯ ä½¿ç”¨ list
                        'status': 'active' if self.model_usage[model_id] > 0 else 'idle',
                        'idle_seconds': (datetime.now() - self.model_last_used[
                            model_id]).total_seconds() if model_id in self.model_last_used else 0
                    }

                return {
                    'total_models': len(self.models),
                    'active_models': len(active_models),
                    'idle_models': len(idle_models),
                    'current_memory_mb': current_memory,
                    'max_memory_mb': self.max_memory_mb,
                    'max_models': self.max_models,
                    'memory_usage_percent': (current_memory / self.max_memory_mb) * 100,
                    'model_usage_percent': (len(self.models) / self.max_models) * 100,
                    'estimated_model_memory_mb': total_estimated_memory,
                    'models': models_status  # ğŸ¯ ä½¿ç”¨ä¿®å¤åçš„å­—å…¸
                }

    def _get_memory_usage(self):
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        process = psutil.Process(os.getpid())
        return process.memory_info().rss / 1024 / 1024  # MB

    async def check_memory_usage(self):
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œé˜²æ­¢å†…å­˜æ³„æ¼"""
        current_memory = self._get_memory_usage()
        # è¿™é‡Œå¯ä»¥ä¿ç•™ä½œä¸ºç‹¬ç«‹çš„å†…å­˜æ£€æŸ¥ï¼Œä½†æ¸…ç†é€»è¾‘å·²ç»é›†æˆåˆ°æ™ºèƒ½æ¸…ç†ä¸­
        if current_memory > 1024:  # è¶…è¿‡1GB
            logger_chatflow.warning(f"âš ï¸ å†…å­˜ä½¿ç”¨è¾ƒé«˜: {current_memory:.1f}MB")
            # è§¦å‘æ™ºèƒ½æ¸…ç†
            await self.check_and_cleanup_if_needed()

        return current_memory

    # ğŸ¯ æ–°å¢ï¼šç£ç›˜ç›‘æ§æ–¹æ³•
    def check_disk_usage(self):
        """æ£€æŸ¥ç£ç›˜ä½¿ç”¨æƒ…å†µï¼Œé˜²æ­¢ç£ç›˜çˆ†æ»¡"""
        disk_info = self.persistence_manager.get_disk_usage()
        if disk_info and disk_info.get('usage_percent', 0) > 90:
            logger_chatflow.warning(f"âš ï¸ ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {disk_info['usage_percent']:.1f}%")
            return False
        return True

    # ğŸ¯ æ–°å¢ï¼šæ‰‹åŠ¨å¤‡ä»½æ¥å£
    def create_manual_backup(self):
        """æ‰‹åŠ¨åˆ›å»ºå¤‡ä»½"""
        return self.persistence_manager.create_manual_backup()

model_manager = DynamicModelManager()

def get_detailed_error():
    """è·å–è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯"""
    # è·å–å½“å‰å¼‚å¸¸ä¿¡æ¯
    exc_type, exc_value, exc_traceback = sys.exc_info()

    # è·å–è°ƒç”¨æ ˆä¿¡æ¯
    stack_summary = traceback.extract_tb(exc_traceback)

    # è·å–æœ€è¿‘çš„é”™è¯¯ä½ç½®
    if stack_summary:
        frame = stack_summary[-1]  # æœ€è¿‘çš„é”™è¯¯ä½ç½®
        filename = frame.filename
        lineno = frame.lineno
        function = frame.name
        code = frame.line

        return {
            'error_type': exc_type.__name__,
            'error_message': str(exc_value),
            'file': filename,
            'line': lineno,
            'function': function,
            'code': code,
            'full_traceback': traceback.format_exc()
        }
    return None

# TODO: Services
# ğŸ¯ å¯åŠ¨æ—¶æ¢å¤æ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
@app.before_serving
async def startup():
    await model_manager.recover_models_on_startup()  # now awaited properly
    model_manager.start_cleanup_task() # clean work

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ - å¢å¼ºç‰ˆæœ¬"""
    status = model_manager.get_model_status()

    health_status = 'healthy'
    warnings = []

    # ğŸ¯ å¥åº·æ£€æŸ¥é€»è¾‘
    if status['memory_usage_percent'] > 90:
        health_status = 'warning'
        warnings.append(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {status['memory_usage_percent']:.1f}%")

    if status['model_usage_percent'] > 90:
        health_status = 'warning'
        warnings.append(f"æ¨¡å‹æ•°é‡æ¥è¿‘ä¸Šé™: {status['model_usage_percent']:.1f}%")

    return jsonify({
        'status': health_status,
        'service': 'dynamic_ai_service',
        'timestamp': datetime.now().isoformat(),
        'model_stats': status,
        'warnings': warnings,
        'memory_usage': status['current_memory_mb']
    })

@app.route('/model/initialize', methods=['POST'])
async def initialize_model():
    """åˆå§‹åŒ–æ¨¡å‹æ¥å£ - åŠ¨æ€åˆ›å»º"""
    data = await request.get_json(silent=True)
    if not data:
        return jsonify({"error": "æ— æ•ˆJSON"}), 400
    model_id = data.get('model_id')
    config_data = data.get('config', {})
    task_id = data.get('task_id', None)
    expire_time = data.get('expire_time')  # éœ€è¦æ·»åŠ è¿™è¡Œ
    if not model_id:
        return jsonify({
            'success': False,
            'message': 'model_id å‚æ•°ä¸èƒ½ä¸ºç©º'
        }), 400

    try:
        if await model_manager.initialize_model(model_id, config_data, task_id, expire_time):
            return jsonify({
                'success': True,
                'message': f'æ¨¡å‹ {model_id} åˆå§‹åŒ–æˆåŠŸ',
                'model_id': model_id,
                'task_id': task_id
            })
        else:
            return jsonify({
                'success': False,
                'message': f'æ¨¡å‹ {model_id} åˆå§‹åŒ–å¤±è´¥'
            }), 500

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æ¨¡å‹ {model_id} åˆå§‹åŒ–å¼‚å¸¸: {str(e)}'
        }), 500

@app.route('/model/extend', methods=['POST'])
async def extend_model():
    """å»¶é•¿æ¨¡å‹è¿‡æœŸæ—¶é—´æ¥å£"""
    data = await request.get_json(silent=True)
    if not data:
        return jsonify({"error": "æ— æ•ˆJSON"}), 400
    model_id = data.get('model_id')
    expire_time = data.get('expire_time')

    if not model_id or not expire_time:
        return jsonify({
            'success': False,
            'message': 'model_id å’Œ expire_time å‚æ•°ä¸èƒ½ä¸ºç©º'
        }), 400

    if model_manager.extend_model_expire_time(model_id, expire_time):
        return jsonify({
            'success': True,
            'message': f'æ¨¡å‹ {model_id} è¿‡æœŸæ—¶é—´å»¶é•¿æˆåŠŸ',
            'model_id': model_id
        })
    else:
        return jsonify({
            'success': False,
            'message': f'æ¨¡å‹ {model_id} æœªæ‰¾åˆ°ï¼Œå»¶é•¿å¤±è´¥'
        }), 404

@app.route('/model/generate', methods=['POST'])
async def generate_response():
    """ç”Ÿæˆè¯æœ¯æ¥å£  åŠ å…œåº•æ¨¡å‹é€»è¾‘ ï¼Œä»»åŠ¡idé‡ŒåŒ…å«ä¸€ä¸ªmodel_id å’Œå…œåº•çš„model_id å¤±è´¥çš„è¯ç”¨å…œåº•åœ¨åˆ¤æ–­ä¸€é"""
    data = await request.get_json(silent=True)
    if not data:
        return jsonify({"error": "æ— æ•ˆJSON"}), 400
    print(data, 'ç”Ÿæˆè¯æœ¯è¯·æ±‚å‚æ•°')
    model_id = data.get('model_id')
    backstop_model = data.get('backstop_model')
    user_input = data.get('user_input', '')
    call_id = data.get('call_id', 'unknown')
    task_id = data.get('task_id')

    if not model_id:
        return jsonify({
            'success': False,
            'message': 'model_id å‚æ•°ä¸èƒ½ä¸ºç©º'
        }), 400
    # ğŸ¯ è®°å½•å®é™…ä½¿ç”¨çš„æ¨¡å‹ID
    actual_used_model = model_id
    # è·å–æ¨¡å‹å®ä¾‹
    # å…ˆç¦ç”¨ æµ‹è¯•å‚æ•° ç›¸å…³ ç”¨å‡çš„
    chatflow = model_manager.get_model(model_id, task_id)
    print(chatflow, 'ä¸´æ—¶chatflow')
    if not chatflow:
        # ä¸å­˜åœ¨ä½¿ç”¨å…œåº•æ¨¡å‹ï¼Œè™½ç„¶model_id å’Œbackstop_modelå¯èƒ½æ˜¯ä¸€ä¸ªä¸å½±å“ï¼Œå¤šåˆ¤æ–­ä¸€æ¬¡çš„äº‹å„¿
        actual_used_model = backstop_model  # ğŸ¯ æ›´æ–°å®é™…ä½¿ç”¨çš„æ¨¡å‹
        chatflow = model_manager.get_model(backstop_model, task_id)

    if not chatflow:
        # æ¨¡å‹æœªæ‰¾åˆ°æˆ–å·²è¿‡æœŸï¼Œé€šçŸ¥PHPæš‚åœä»»åŠ¡
        if task_id:
            model_manager.notify_php_task_pause(task_id, model_id, "model_not_found_or_expired")

        return jsonify({
            'success': False,
            'message': f'æ¨¡å‹ {model_id} å’Œå…œåº•æ¨¡å‹ {backstop_model} éƒ½æœªæ‰¾åˆ°æˆ–å·²è¿‡æœŸ',
            'error_code': 'MODEL_NOT_FOUND'
        }), 404

    try:
        # é…ç½®
        conv_config = {"configurable": {"thread_id": f"call_{call_id}"}}
        # print(state, 'ç”Ÿæˆè¯æœ¯çš„è¯·æ±‚å‚æ•°')
        state = await chatflow.ainvoke({"messages": [HumanMessage(content=user_input)]}, config=conv_config)
        print(state, 'state---ç»“æœ')

        # æå–AIå›å¤ - metadata ä¸­ä¸æœ€åä¸€æ¡çš„ reply_round ç›¸åŒçš„æ‰€æœ‰æ¡ç›®
        current_round_metadata = state["metadata"][-1] # è·å–æœ€åä¸€æ¡çš„ reply_round
        print(json.dumps(current_round_metadata, indent=4, ensure_ascii=False), 'è¾“å‡ºmetadata')
        # åˆ›å»ºè¾“å‡ºå†…å®¹
        output = {
            'success': True,
            # å½“å‰å›å¤çš„è¯æœ¯å†…å®¹
            'content': current_round_metadata.get("content", []),
            'end_call': current_round_metadata.get("end_call", False),
            'reply_round': current_round_metadata.get("reply_round", 0),
            'token_used': current_round_metadata.get("token_used", 0),
            'total_token_used': current_round_metadata.get("total_token_used", 0),
            # å†å²è®°å½• - åŒä¸€å›å¤è½®(reply_round) å†å²è®°å½•æ˜¯ä¸€æ ·çš„ï¼Œéƒ½æ˜¯æœ€åä¸€è½®çš„
            'conversation_history_detail': state["metadata"],
            'call_id': call_id,
            'model_id': actual_used_model,
            'timestamp': datetime.now().isoformat()
        }
        print(json.dumps(output, indent=4, ensure_ascii=False), 'è¾“å‡ºç»“æœ')
        return jsonify(output)

    except Exception as e:
        error_info = get_detailed_error()
        if error_info:
            print(f"é”™è¯¯ç±»å‹: {error_info['error_type']}")
            print(f"é”™è¯¯ä¿¡æ¯: {error_info['error_message']}")
            print(f"æ–‡ä»¶: {error_info['file']}")
            print(f"è¡Œå·: {error_info['line']}")
            print(f"å‡½æ•°: {error_info['function']}")
            print(f"ä»£ç : {error_info['code']}")
            print("å®Œæ•´å †æ ˆ:")
            print(error_info['full_traceback'])
        logger_chatflow.error(f"ç”Ÿæˆè¯æœ¯å¤±è´¥ - æ¨¡å‹: {actual_used_model}, å‘¼å«: {call_id}, é”™è¯¯: {str(e)}ï¼Œå®Œæ•´å †æ ˆï¼š{error_info['full_traceback']}")
        return jsonify({
            'success': False,
            'message': f'è¯æœ¯ç”Ÿæˆå¤±è´¥: {str(e)}'
        }), 500
    finally:
        # é‡Šæ”¾æ¨¡å‹ä½¿ç”¨è®¡æ•°
        if task_id:
            model_manager.release_model(actual_used_model, task_id)

@app.route('/model/again', methods=['POST'])
async def again_model():
    """é”€æ¯æ¨¡å‹æ¥å£"""
    data = await request.get_json(silent=True)
    if not data:
        return jsonify({"error": "æ— æ•ˆJSON"}), 400
    model_id = data.get('model_id')
    
    if not model_id:
        return jsonify({
            'success': False,
            'message': 'model_id å‚æ•°ä¸èƒ½ä¸ºç©º'
        }), 400

    if model_manager.again_model(model_id):
        return jsonify({
            'success': True,
            'message': f'æ¨¡å‹ {model_id} é”€æ¯æˆåŠŸ'
        })
    
    else:
        return jsonify({
            'success': False,
            'message': f'æ¨¡å‹ {model_id} é”€æ¯å¤±è´¥ï¼Œå¯èƒ½ä»æœ‰ä»»åŠ¡åœ¨ä½¿ç”¨'
        }), 400

@app.route('/model/destroy', methods=['POST'])
async def destroy_model():
    """é”€æ¯æ¨¡å‹æ¥å£"""
    data = await request.get_json(silent=True)
    if not data:
        return jsonify({"error": "æ— æ•ˆJSON"}), 400
    model_id = data.get('model_id')
    task_id = data.get('task_id')
    force = data.get('force', False)
    
    if not model_id:
        return jsonify({
            'success': False,
            'message': 'model_id å‚æ•°ä¸èƒ½ä¸ºç©º'
        }), 400

    if model_manager.destroy_model(model_id, force):
        return jsonify({
            'success': True,
            'message': f'æ¨¡å‹ {model_id} é”€æ¯æˆåŠŸ'
        })
    else:
        return jsonify({
            'success': False,
            'message': f'æ¨¡å‹ {model_id} é”€æ¯å¤±è´¥ï¼Œå¯èƒ½ä»æœ‰ä»»åŠ¡åœ¨ä½¿ç”¨'
        }), 400

@app.route('/model/status', methods=['GET'])
def get_model_status():
    """è·å–æ¨¡å‹çŠ¶æ€"""
    model_id = request.args.get('model_id')
    status = model_manager.get_model_status(model_id)
    return jsonify(status)

@app.route('/model/cleanup', methods=['POST'])
async def cleanup_models():
    """æ‰‹åŠ¨è§¦å‘æ¸…ç†ç©ºé—²æ¨¡å‹ - ğŸ¯ ä¿®å¤è¿™é‡Œ"""
    data = await request.get_json(silent=True)
    if not data:
        return jsonify({"error": "æ— æ•ˆJSON"}), 400
    force = data.get('force', False)

    # ğŸ¯ æ ¹æ®forceå‚æ•°å†³å®šæ¸…ç†ç­–ç•¥
    if force:
        result = await model_manager.cleanup_idle_models(force_reason='manual')
    else:
        result = await model_manager.cleanup_idle_models()  # æ­£å¸¸æ¸…ç†

    status = model_manager.get_model_status()
    return jsonify({
        'success': True,
        'message': 'ç©ºé—²æ¨¡å‹æ¸…ç†å®Œæˆ',
        'cleanup_result': result,  # ğŸ¯ è¿”å›æ¸…ç†è¯¦æƒ…
        'current_stats': {
            'total_models': status['total_models'],
            'active_models': status['active_models'],
            'current_memory_mb': status['current_memory_mb']
        }
    })

@app.route('/model/persistence/backup', methods=['POST'])
def create_manual_backup():
    """æ‰‹åŠ¨åˆ›å»ºæŒä¹…åŒ–æ•°æ®å¤‡ä»½"""
    try:
        if model_manager.create_manual_backup():
            return jsonify({
                'success': True,
                'message': 'æ‰‹åŠ¨å¤‡ä»½åˆ›å»ºæˆåŠŸ'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'æ‰‹åŠ¨å¤‡ä»½åˆ›å»ºå¤±è´¥'
            }), 500
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'åˆ›å»ºå¤‡ä»½å¼‚å¸¸: {str(e)}'
        }), 500

@app.route('/model/persistence/status', methods=['GET'])
def get_persistence_status():
    """è·å–æŒä¹…åŒ–çŠ¶æ€"""
    try:
        disk_info = model_manager.persistence_manager.get_disk_usage()
        models_count = len([f for f in os.listdir(model_manager.persistence_manager.models_dir)
                            if f.endswith('.json')])
        backups_count = len([f for f in os.listdir(model_manager.persistence_manager.backup_dir)
                             if f.endswith('.json')])

        return jsonify({
            'success': True,
            'persistence_path': model_manager.persistence_manager.base_path,
            'models_persisted': models_count,
            'backups_count': backups_count,
            'disk_usage': disk_info,
            'warnings': ['ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜'] if disk_info.get('usage_percent', 0) > 90 else []
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–æŒä¹…åŒ–çŠ¶æ€å¤±è´¥: {str(e)}'
        }), 500

@app.route("/keyword_match", methods=["POST"])
async def match_keywords():
    try:
        # Parse JSON body
        data = await request.get_json(silent=True)
        if not data:
            return jsonify({"error": "æ— æ•ˆJSON"}), 400

        keywords = data.get("keywords")
        sentence = data.get("sentence")

        # Input validation
        if not isinstance(keywords, list):
            return jsonify({"error": "å…³é”®è¯è¾“å…¥åº”ä¸ºåˆ—è¡¨"}), 400
        if not keywords:
            return jsonify({"matched": False})
        if not isinstance(sentence, str) or not sentence.strip():
            return jsonify({"matched": False})

        # Build intention for your matcher
        intention_list = [
            {
                "intention_id": "keyword_matching_service",
                "intention_name": "å…³é”®è¯åŒ¹é…æœåŠ¡",
                "keywords": keywords
            }
        ]

        matcher = KeywordMatcher(intention_list)
        result = matcher.analyze_sentence(sentence)

        return jsonify({"matched": bool(result)})

    except Exception as e:
        logger_chatflow.error(f"å…³é”®è¯åŒ¹é…é”™è¯¯: {str(e)}")
        return jsonify({"error": "Internal matching error"}), 500

# TODO: Start the service
def start_dynamic_service(port=5002):
    """å¯åŠ¨åŠ¨æ€æ¨¡å‹æœåŠ¡ - è°ƒè¯•ç‰ˆæœ¬"""
    logging.getLogger("hypercorn").setLevel(logging.INFO)
    hypercorn_logger = logging.getLogger("hypercorn.access")

    logger_chatflow.info(f"å¯åŠ¨åŠ¨æ€AIæ¨¡å‹æœåŠ¡ï¼Œç«¯å£: {port}")
    logger_chatflow.info("æœåŠ¡ç‰¹ç‚¹: åŠ¨æ€æ¨¡å‹ç®¡ç†ï¼ŒæŒ‰éœ€åˆ›å»ºï¼Œè‡ªåŠ¨æ¸…ç†")

    config = Config()
    config.bind = [f"0.0.0.0:{port}"]
    config.accesslog = hypercorn_logger
    config.backlog = 1024
    config.timeout_keep_alive = 30
    config.startup_timeout = 720.0
    config.shutdown_timeout = 30.0
    config.use_reloader = False
    config.lifespan = "off"  # âœ… CRITICAL: disable ASGI lifespan

    logger_chatflow.info(f"Hypercorn é…ç½®:")
    logger_chatflow.info(f"  - ç«¯å£: {port}")
    logger_chatflow.info(f"  - å¯åŠ¨è¶…æ—¶: {config.startup_timeout}s")
    logger_chatflow.info(f"  - Lifespan: {config.lifespan}")

    try:
        asyncio.run(serve(app, config))
    except Exception as e:
        logger_chatflow.error(f"æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise

if __name__ == '__main__':
    start_dynamic_service()
# persistence_manager.py
import json
import os
import shutil
from datetime import datetime, timedelta
import logging
from threading import RLock


class ModelPersistenceManager:
    """æ¨¡å‹æŒä¹…åŒ–ç®¡ç†å™¨ - ä¸“æ³¨æ¨¡å‹é…ç½®"""

    def __init__(self, base_path=None):
        # ğŸ¯ ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ä¸‹çš„ persistence æ–‡ä»¶å¤¹
        if base_path is None:
            # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œç„¶åæ„å»ºç›¸å¯¹è·¯å¾„
            current_dir = os.path.dirname(os.path.abspath(__file__))
            current_dir += '/../'
            base_path = os.path.join(current_dir, "persistence")
        print(base_path, 'base_path')
        self.base_path = base_path
        self.models_dir = os.path.join(base_path, "models")
        self.backup_dir = os.path.join(base_path, "../backups")
        self.recovery_log = os.path.join(base_path, "recovery.log")
        self.lock = RLock()

        # åˆ›å»ºç›®å½•ç»“æ„
        self._ensure_directories()
        self._setup_logging()

    def _ensure_directories(self):
        """ç¡®ä¿ç›®å½•ç»“æ„å­˜åœ¨"""
        for directory in [self.models_dir, self.backup_dir]:
            os.makedirs(directory, exist_ok=True)

    def _setup_logging(self):
        """è®¾ç½®æ¢å¤æ—¥å¿—"""
        self.logger = logging.getLogger('model_persistence')
        handler = logging.FileHandler(self.recovery_log, encoding='utf-8')
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
        self.logger.setLevel(logging.INFO)

    def save_model_config(self, model_id, model_data):
        """ä¿å­˜æ¨¡å‹é…ç½®åˆ°æ–‡ä»¶"""
        with self.lock:
            try:
                file_path = os.path.join(self.models_dir, f"{model_id}.json")

                # å‡†å¤‡æŒä¹…åŒ–æ•°æ®
                persist_data = {
                    'model_id': model_id,
                    'config': model_data.get('config', {}),
                    'created_time': model_data.get('created_time').isoformat() if model_data.get(
                        'created_time') else None,
                    'expire_time': model_data.get('expire_time'),
                    'memory_usage': model_data.get('memory_usage', 0),
                    'status': model_data.get('status', 'active'),
                    'last_used': model_data.get('last_used').isoformat() if model_data.get('last_used') else None,
                    'persisted_at': datetime.now().isoformat()
                }

                # å†™å…¥æ–‡ä»¶
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(persist_data, f, ensure_ascii=False, indent=2)

                self.logger.info(f"âœ… æ¨¡å‹é…ç½®å·²ä¿å­˜: {model_id}")
                return True

            except Exception as e:
                self.logger.error(f"âŒ ä¿å­˜æ¨¡å‹é…ç½®å¤±è´¥ {model_id}: {str(e)}")
                return False

    def load_model_configs(self):
        """åŠ è½½æ‰€æœ‰æ¨¡å‹é…ç½®"""
        with self.lock:
            models = {}
            try:
                if not os.path.exists(self.models_dir):
                    return models

                for filename in os.listdir(self.models_dir):
                    if filename.endswith('.json'):
                        model_id = filename[:-5]
                        file_path = os.path.join(self.models_dir, filename)

                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                model_data = json.load(f)

                            # è½¬æ¢æ—¶é—´å­—æ®µ
                            if model_data.get('created_time'):
                                model_data['created_time'] = datetime.fromisoformat(model_data['created_time'])
                            if model_data.get('last_used'):
                                model_data['last_used'] = datetime.fromisoformat(model_data['last_used'])

                            models[model_id] = model_data
                            self.logger.info(f"ğŸ“¥ åŠ è½½æ¨¡å‹é…ç½®: {model_id}")

                        except Exception as e:
                            self.logger.error(f"âŒ åŠ è½½æ¨¡å‹é…ç½®å¤±è´¥ {filename}: {str(e)}")
                            continue

            except Exception as e:
                self.logger.error(f"âŒ åŠ è½½æ¨¡å‹é…ç½®ç›®å½•å¤±è´¥: {str(e)}")

            return models

    def delete_model_config(self, model_id):
        """åˆ é™¤æ¨¡å‹é…ç½®"""
        with self.lock:
            try:
                file_path = os.path.join(self.models_dir, f"{model_id}.json")
                if os.path.exists(file_path):
                    # ğŸ¯ è‡ªåŠ¨å¤‡ä»½åˆ°å¤‡ä»½ç›®å½•
                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                    backup_path = os.path.join(self.backup_dir, f"{model_id}_{timestamp}.json")
                    shutil.copy2(file_path, backup_path)

                    # åˆ é™¤åŸæ–‡ä»¶
                    os.remove(file_path)
                    self.logger.info(f"ğŸ—‘ï¸ æ¨¡å‹é…ç½®å·²åˆ é™¤: {model_id}")

                    # ğŸ¯ è‡ªåŠ¨æ¸…ç†æ—§å¤‡ä»½
                    self._cleanup_old_backups()

                return True
            except Exception as e:
                self.logger.error(f"âŒ åˆ é™¤æ¨¡å‹é…ç½®å¤±è´¥ {model_id}: {str(e)}")
                return False

    def _cleanup_old_backups(self, keep_days=7):
        """æ¸…ç†æ—§å¤‡ä»½ - åœ¨åˆ é™¤æ¨¡å‹æ—¶è‡ªåŠ¨è°ƒç”¨"""
        try:
            current_time = datetime.now()
            deleted_count = 0

            for filename in os.listdir(self.backup_dir):
                if filename.endswith('.json'):
                    file_path = os.path.join(self.backup_dir, filename)

                    # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                    file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))

                    # æ£€æŸ¥æ˜¯å¦è¶…è¿‡ä¿ç•™æœŸé™
                    if (current_time - file_mtime).days > keep_days:
                        os.remove(file_path)
                        deleted_count += 1
                        self.logger.info(f"ğŸ§¹ æ¸…ç†æ—§å¤‡ä»½: {filename}")

            if deleted_count > 0:
                self.logger.info(f"âœ… è‡ªåŠ¨æ¸…ç†å®Œæˆ: åˆ é™¤äº† {deleted_count} ä¸ªæ—§å¤‡ä»½")

        except Exception as e:
            self.logger.error(f"âŒ è‡ªåŠ¨æ¸…ç†å¤‡ä»½å¤±è´¥: {str(e)}")

    def create_manual_backup(self):
        """æ‰‹åŠ¨åˆ›å»ºå®Œæ•´å¤‡ä»½"""
        with self.lock:
            try:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                backup_path = os.path.join(self.backup_dir, f"manual_backup_{timestamp}")

                shutil.copytree(self.models_dir, backup_path)
                self.logger.info(f"ğŸ’¾ åˆ›å»ºæ‰‹åŠ¨å¤‡ä»½: {backup_path}")
                return True

            except Exception as e:
                self.logger.error(f"âŒ åˆ›å»ºæ‰‹åŠ¨å¤‡ä»½å¤±è´¥: {str(e)}")
                return False

    def get_disk_usage(self):
        """è·å–ç£ç›˜ä½¿ç”¨æƒ…å†µ"""
        try:
            total, used, free = shutil.disk_usage(self.base_path)
            return {
                'total_mb': total // (1024 * 1024),
                'used_mb': used // (1024 * 1024),
                'free_mb': free // (1024 * 1024),
                'usage_percent': (used / total) * 100
            }
        except Exception as e:
            self.logger.error(f"âŒ è·å–ç£ç›˜ä½¿ç”¨æƒ…å†µå¤±è´¥: {str(e)}")
            return {}
